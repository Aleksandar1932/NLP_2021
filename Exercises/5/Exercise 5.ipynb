{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_embeddings(file_name, vocabulary):\n",
    "    \"\"\"\n",
    "    Loads word embeddings from the file with the given name.\n",
    "    :param file_name: name of the file containing word embeddings\n",
    "    :type file_name: str\n",
    "    :param vocabulary: captions vocabulary\n",
    "    :type vocabulary: numpy.array\n",
    "    :return: word embeddings\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    embeddings = dict()\n",
    "    with open(file_name, 'r', encoding='utf-8') as doc:\n",
    "        line = doc.readline()\n",
    "        while line != '':\n",
    "            line = line.rstrip('\\n').lower()\n",
    "            parts = line.split(' ')\n",
    "            vals = np.array(parts[1:], dtype=np.float)\n",
    "            if parts[0] in vocabulary:\n",
    "                embeddings[parts[0]] = vals\n",
    "            line = doc.readline()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_embedding_weights(vocabulary, embedding_size, embedding_type, path='.'):\n",
    "    print(\"local\")\n",
    "    \"\"\"\n",
    "    Creates and loads embedding weights.\n",
    "    :param vocabulary: vocabulary\n",
    "    :type vocabulary: numpy.array\n",
    "    :param embedding_size: embedding size\n",
    "    :type embedding_size: int\n",
    "    :param embedding_type: type of the pre-trained embeddings\n",
    "    :type embedding_type: string\n",
    "    :return: embedding weights\n",
    "    :rtype: numpy.array\n",
    "    \"\"\"\n",
    "    if os.path.exists(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl'):\n",
    "        with open(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl', 'rb') as f:\n",
    "            embedding_matrix = pickle.load(f)\n",
    "    else:\n",
    "        print('Creating embedding weights...')\n",
    "        if embedding_type == 'glove':\n",
    "            embeddings = load_embeddings(f'{path}/glove.6B.{embedding_size}d.txt', vocabulary)\n",
    "        else:\n",
    "          embeddings = load_embeddings(f'{path}/word2vecSG.iSarcasamEval.{embedding_size}d.txt', vocabulary)\n",
    "        embedding_matrix = np.zeros((len(vocabulary), embedding_size))\n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in embeddings.keys():\n",
    "                embedding_matrix[i] = embeddings[vocabulary[i]]\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.standard_normal(embedding_size)\n",
    "        with open(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl', 'wb') as f:\n",
    "            pickle.dump(embedding_matrix, f)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 12:03:23.555210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-05 12:03:23.555249: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from scripts.word_embeddings import load_embedding_weights\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('data/train.En.csv', usecols=['tweet', 'rephrase']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data['tweet_tokens'] = data['tweet'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    data['rephrase_tokens'] = data['rephrase'].apply(lambda x: word_tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_start_end(data):\n",
    "    data['tweet_tokens'] = data['tweet_tokens'].apply(lambda x: np.concatenate((['<START>'], x, ['</END>'])))\n",
    "    data['rephrase_tokens'] = data['rephrase_tokens'].apply(lambda x: np.concatenate((['<START>'], x, ['</END>'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(sentence_tokens):\n",
    "    vocab = set()\n",
    "    for tokens in sentence_tokens:\n",
    "        vocab.update(tokens)\n",
    "    \n",
    "    vocab = list(vocab)\n",
    "    word_to_id = {word: index for word, index in zip(vocab, range(len(vocab)))}\n",
    "    id_to_word = {index: word for word, index in zip(vocab, range(len(vocab)))}\n",
    "    return vocab, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(sentences, rephrases):\n",
    "    input_sentences, input_rephrases, next_words = [], [], []\n",
    "\n",
    "    for sentence, rephrase in zip(sentences, rephrases):\n",
    "        for i in range(1, len(rephrase)):\n",
    "            input_sentences.append(sentence)\n",
    "            input_rephrases.append(rephrase[:i])\n",
    "            next_words.append(rephrase[i])\n",
    "\n",
    "    return input_sentences, input_rephrases, next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(padding_size, vocabulary_size, embedding_size, embeddings=None, name=\"\"):\n",
    "    # encoder\n",
    "    encoder_inputs = Input(shape=(padding_size,), name='encoder_inputs')\n",
    "    encoder_embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_size,\n",
    "                                #   weights=[embeddings], \n",
    "                                  trainable=False)(encoder_inputs)\n",
    "\n",
    "    encoder = LSTM(128, return_state=True, name='encoder')\n",
    "    encoder(encoder_embedding)\n",
    "\n",
    "    _, state_h, state_c = encoder(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # decoder\n",
    "    decoder_inputs = Input(shape=(padding_size,), name='decoder_inputs')\n",
    "    decoder_embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_size,\n",
    "                                #   weights=[embeddings], \n",
    "                                  trainable=False)(decoder_inputs)\n",
    "\n",
    "    decoder = LSTM(128, return_state=True, name='decoder')\n",
    "    decoder_outputs, _, _ =decoder(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "    decoder_outputs = Dense(vocabulary_size, activation='softmax', name='decoder_dense')(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "    model._name = name\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rephrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>I do not like when professors don’t write out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  The only thing I got from college is a caffein...   \n",
       "1  I love it when professors draw a big question ...   \n",
       "2  Remember the hundred emails from companies whe...   \n",
       "3  Today my pop-pop told me I was not “forced” to...   \n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...   \n",
       "\n",
       "                                            rephrase  \n",
       "0  College is really difficult, expensive, tiring...  \n",
       "1  I do not like when professors don’t write out ...  \n",
       "2  I, at the bare minimum, wish companies actuall...  \n",
       "3  Today my pop-pop told me I was not \"forced\" to...  \n",
       "4  I would say Ted Cruz is an asshole and doesn’t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>rephrase_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>[the, only, thing, i, got, from, college, is, ...</td>\n",
       "      <td>[college, is, really, difficult, ,, expensive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>I do not like when professors don’t write out ...</td>\n",
       "      <td>[i, love, it, when, professors, draw, a, big, ...</td>\n",
       "      <td>[i, do, not, like, when, professors, don, ’, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "      <td>[remember, the, hundred, emails, from, compani...</td>\n",
       "      <td>[i, ,, at, the, bare, minimum, ,, wish, compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "      <td>[today, my, pop-pop, told, me, i, was, not, “,...</td>\n",
       "      <td>[today, my, pop-pop, told, me, i, was, not, ``...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
       "      <td>[@, volphancarol, @, littlewhitty, @, mystical...</td>\n",
       "      <td>[i, would, say, ted, cruz, is, an, asshole, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  The only thing I got from college is a caffein...   \n",
       "1  I love it when professors draw a big question ...   \n",
       "2  Remember the hundred emails from companies whe...   \n",
       "3  Today my pop-pop told me I was not “forced” to...   \n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...   \n",
       "\n",
       "                                            rephrase  \\\n",
       "0  College is really difficult, expensive, tiring...   \n",
       "1  I do not like when professors don’t write out ...   \n",
       "2  I, at the bare minimum, wish companies actuall...   \n",
       "3  Today my pop-pop told me I was not \"forced\" to...   \n",
       "4  I would say Ted Cruz is an asshole and doesn’t...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [the, only, thing, i, got, from, college, is, ...   \n",
       "1  [i, love, it, when, professors, draw, a, big, ...   \n",
       "2  [remember, the, hundred, emails, from, compani...   \n",
       "3  [today, my, pop-pop, told, me, i, was, not, “,...   \n",
       "4  [@, volphancarol, @, littlewhitty, @, mystical...   \n",
       "\n",
       "                                     rephrase_tokens  \n",
       "0  [college, is, really, difficult, ,, expensive,...  \n",
       "1  [i, do, not, like, when, professors, don, ’, t...  \n",
       "2  [i, ,, at, the, bare, minimum, ,, wish, compan...  \n",
       "3  [today, my, pop-pop, told, me, i, was, not, ``...  \n",
       "4  [i, would, say, ted, cruz, is, an, asshole, an...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>rephrase_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>[&lt;START&gt;, the, only, thing, i, got, from, coll...</td>\n",
       "      <td>[&lt;START&gt;, college, is, really, difficult, ,, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>I do not like when professors don’t write out ...</td>\n",
       "      <td>[&lt;START&gt;, i, love, it, when, professors, draw,...</td>\n",
       "      <td>[&lt;START&gt;, i, do, not, like, when, professors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "      <td>[&lt;START&gt;, remember, the, hundred, emails, from...</td>\n",
       "      <td>[&lt;START&gt;, i, ,, at, the, bare, minimum, ,, wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "      <td>[&lt;START&gt;, today, my, pop-pop, told, me, i, was...</td>\n",
       "      <td>[&lt;START&gt;, today, my, pop-pop, told, me, i, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
       "      <td>[&lt;START&gt;, @, volphancarol, @, littlewhitty, @,...</td>\n",
       "      <td>[&lt;START&gt;, i, would, say, ted, cruz, is, an, as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  The only thing I got from college is a caffein...   \n",
       "1  I love it when professors draw a big question ...   \n",
       "2  Remember the hundred emails from companies whe...   \n",
       "3  Today my pop-pop told me I was not “forced” to...   \n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...   \n",
       "\n",
       "                                            rephrase  \\\n",
       "0  College is really difficult, expensive, tiring...   \n",
       "1  I do not like when professors don’t write out ...   \n",
       "2  I, at the bare minimum, wish companies actuall...   \n",
       "3  Today my pop-pop told me I was not \"forced\" to...   \n",
       "4  I would say Ted Cruz is an asshole and doesn’t...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0  [<START>, the, only, thing, i, got, from, coll...   \n",
       "1  [<START>, i, love, it, when, professors, draw,...   \n",
       "2  [<START>, remember, the, hundred, emails, from...   \n",
       "3  [<START>, today, my, pop-pop, told, me, i, was...   \n",
       "4  [<START>, @, volphancarol, @, littlewhitty, @,...   \n",
       "\n",
       "                                     rephrase_tokens  \n",
       "0  [<START>, college, is, really, difficult, ,, e...  \n",
       "1  [<START>, i, do, not, like, when, professors, ...  \n",
       "2  [<START>, i, ,, at, the, bare, minimum, ,, wis...  \n",
       "3  [<START>, today, my, pop-pop, told, me, i, was...  \n",
       "4  [<START>, i, would, say, ted, cruz, is, an, as...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_start_end(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['tweet_tokens'].values\n",
    "rephrases = df['rephrase_tokens'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, word_to_id, id_to_word = create_vocabulary(np.concatenate((sentences, rephrases)))\n",
    "\n",
    "df['tweet_indices'] = df['tweet_tokens'].apply(lambda x: np.array([word_to_id[i] for i in x]))\n",
    "sentence_indices = df['tweet_indices'].values\n",
    "\n",
    "df['rephrase_indices'] = df['rephrase_tokens'].apply(lambda x: np.array([word_to_id[i] for i in x]))\n",
    "rephrase_indices = df['rephrase_indices'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_embedding_weights(vocabulary, 50, 'glove', \"/mnt/d/Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_rephrases, \\\n",
    "    test_sentences, test_rephrases = train_test_split(sentence_indices, rephrase_indices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences, input_rephrases, next_words = create_train_data(train_sentences, train_rephrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences = pad_sequences(input_sentences, maxlen=10)\n",
    "padded_rephrases = pad_sequences(input_rephrases, maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(list(word_to_id.values()))\n",
    "next_words = label_binarizer.transform(next_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandar/envs/nlp-2021-n/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 - 5s - loss: 7.5857 - accuracy: 0.0387 - 5s/epoch - 73ms/step\n",
      "Epoch 2/10\n",
      "63/63 - 2s - loss: 6.4355 - accuracy: 0.0434 - 2s/epoch - 27ms/step\n",
      "Epoch 3/10\n",
      "63/63 - 2s - loss: 6.3038 - accuracy: 0.0434 - 2s/epoch - 27ms/step\n",
      "Epoch 4/10\n",
      "63/63 - 2s - loss: 6.2700 - accuracy: 0.0417 - 2s/epoch - 28ms/step\n",
      "Epoch 5/10\n",
      "63/63 - 2s - loss: 6.2546 - accuracy: 0.0434 - 2s/epoch - 27ms/step\n",
      "Epoch 6/10\n",
      "63/63 - 2s - loss: 6.2465 - accuracy: 0.0434 - 2s/epoch - 27ms/step\n",
      "Epoch 7/10\n",
      "63/63 - 2s - loss: 6.2385 - accuracy: 0.0434 - 2s/epoch - 28ms/step\n",
      "Epoch 8/10\n",
      "63/63 - 2s - loss: 6.2361 - accuracy: 0.0404 - 2s/epoch - 26ms/step\n",
      "Epoch 9/10\n",
      "63/63 - 2s - loss: 6.2304 - accuracy: 0.0434 - 2s/epoch - 26ms/step\n",
      "Epoch 10/10\n",
      "63/63 - 2s - loss: 6.2255 - accuracy: 0.0434 - 2s/epoch - 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa441a7640>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(10, len(vocabulary), 50, embeddings, name='lstm_seq2seq')\n",
    "\n",
    "model.fit([np.array(padded_sentences), np.array(padded_rephrases)],\n",
    "              np.array(next_words),\n",
    "              batch_size=64, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('EncoderDecoder.h5')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d0b1b3f612c4c5e51656c8d0ea12cc8bdc13c9ac193c394dc1e17c8d0fd734"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp-2021-n': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
