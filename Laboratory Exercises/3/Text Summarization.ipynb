{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 23:31:19.467182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 23:31:19.467225: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from scripts.utils import load_data\n",
    "from scripts.utils import nlp_pipeline\n",
    "from scripts.utils import create_vocabulary\n",
    "from scripts.loader import load_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_start_end(data):\n",
    "    data['text_tokens'] = data['text_tokens'].apply(lambda x: np.concatenate((['<START>'], x, ['</END>'])))\n",
    "    data['summary_tokens'] = data['summary_tokens'].apply(lambda x: np.concatenate((['<START>'], x, ['</END>'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(texts, summaries):\n",
    "    input_texts, input_summaries, next_words = [], [], []\n",
    "\n",
    "    for sentence, rephrase in zip(texts, summaries):\n",
    "        for i in range(1, len(rephrase)):\n",
    "            input_texts.append(sentence)\n",
    "            input_summaries.append(rephrase[:i])\n",
    "            next_words.append(rephrase[i])\n",
    "\n",
    "    return input_texts, input_summaries, next_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qq00fa8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1464... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">scarlet-fire-1</strong>: <a href=\"https://wandb.ai/aleksandar1932/%5BNLP%5D%20lab-05%20%7C%20text-summarization/runs/3qq00fa8\" target=\"_blank\">https://wandb.ai/aleksandar1932/%5BNLP%5D%20lab-05%20%7C%20text-summarization/runs/3qq00fa8</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211209_072027-3qq00fa8/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3qq00fa8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-12-09 07:25:41.276551: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-09 07:25:41.276598: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/%5BNLP%5D%20lab-05%20%7C%20text-summarization/runs/16wx92uy\" target=\"_blank\">polar-sponge-2</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/%5BNLP%5D%20lab-05%20%7C%20text-summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"[NLP] lab-05 | text-summarization\", job_type=\"load_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>, and is very, very accurate .\\r\\n but for the...</td>\n",
       "      <td>This unit is generally quite accurate.  \\r\\nSe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>The room was not overly big, but clean and ve...</td>\n",
       "      <td>The rooms were not large but were clean and ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>After I plugged it in to my USB hub on my com...</td>\n",
       "      <td>Battery life is exceptional.\\r\\nThe Kindle can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>short battery life  I moved up from an 8gb .\\...</td>\n",
       "      <td>The battery life is too short.\\r\\nThe time bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...</td>\n",
       "      <td>The battery life is longer then 5 hours.\\r\\nBu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                                text  \\\n",
       "0  , and is very, very accurate .\\r\\n but for the...   \n",
       "1   The room was not overly big, but clean and ve...   \n",
       "2   After I plugged it in to my USB hub on my com...   \n",
       "3   short battery life  I moved up from an 8gb .\\...   \n",
       "4  6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...   \n",
       "\n",
       "                                             summary  \n",
       "0  This unit is generally quite accurate.  \\r\\nSe...  \n",
       "1  The rooms were not large but were clean and ve...  \n",
       "2  Battery life is exceptional.\\r\\nThe Kindle can...  \n",
       "3  The battery life is too short.\\r\\nThe time bet...  \n",
       "4  The battery life is longer then 5 hours.\\r\\nBu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload raw data as artifact to WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f0eb28433a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = wandb.Artifact(\n",
    "    \"opinosis-raw\", type=\"dataset\",\n",
    "    description=\"Raw OPINOSIS dataset\",\n",
    "    metadata={\"source\": \"https://archive.ics.uci.edu/ml/datasets/Opinosis+Opinion+%26frasl%3B+Review\",\n",
    "                \"sizes\": len(df)}\n",
    ")\n",
    "\n",
    "complete_data = wandb.Table(data=df, columns=df.columns)\n",
    "raw_data.add(complete_data, \"Complete dataset\")\n",
    "run.log_artifact(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>summary_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>, and is very, very accurate .\\r\\n but for the...</td>\n",
       "      <td>This unit is generally quite accurate.  \\r\\nSe...</td>\n",
       "      <td>[accurate, part, find, garmin, software, provi...</td>\n",
       "      <td>[unit, generally, quite, accurate, set-up, usa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>The room was not overly big, but clean and ve...</td>\n",
       "      <td>The rooms were not large but were clean and ve...</td>\n",
       "      <td>[room, overly, big, clean, comfortable, beds, ...</td>\n",
       "      <td>[rooms, large, clean, comfortable, bathroom, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>After I plugged it in to my USB hub on my com...</td>\n",
       "      <td>Battery life is exceptional.\\r\\nThe Kindle can...</td>\n",
       "      <td>[plugged, usb, hub, computer, charge, battery,...</td>\n",
       "      <td>[battery, life, exceptional, kindle, run, days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>short battery life  I moved up from an 8gb .\\...</td>\n",
       "      <td>The battery life is too short.\\r\\nThe time bet...</td>\n",
       "      <td>[short, battery, life, moved, 8gb, love, ipod,...</td>\n",
       "      <td>[battery, life, short, time, chargers, enough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...</td>\n",
       "      <td>The battery life is longer then 5 hours.\\r\\nBu...</td>\n",
       "      <td>[6ghz, 533fsb, cpu, glossy, display, 3, cell, ...</td>\n",
       "      <td>[battery, life, longer, 5, hours, due, battery...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                                text  \\\n",
       "0  , and is very, very accurate .\\r\\n but for the...   \n",
       "1   The room was not overly big, but clean and ve...   \n",
       "2   After I plugged it in to my USB hub on my com...   \n",
       "3   short battery life  I moved up from an 8gb .\\...   \n",
       "4  6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This unit is generally quite accurate.  \\r\\nSe...   \n",
       "1  The rooms were not large but were clean and ve...   \n",
       "2  Battery life is exceptional.\\r\\nThe Kindle can...   \n",
       "3  The battery life is too short.\\r\\nThe time bet...   \n",
       "4  The battery life is longer then 5 hours.\\r\\nBu...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [accurate, part, find, garmin, software, provi...   \n",
       "1  [room, overly, big, clean, comfortable, beds, ...   \n",
       "2  [plugged, usb, hub, computer, charge, battery,...   \n",
       "3  [short, battery, life, moved, 8gb, love, ipod,...   \n",
       "4  [6ghz, 533fsb, cpu, glossy, display, 3, cell, ...   \n",
       "\n",
       "                                      summary_tokens  \n",
       "0  [unit, generally, quite, accurate, set-up, usa...  \n",
       "1  [rooms, large, clean, comfortable, bathroom, s...  \n",
       "2  [battery, life, exceptional, kindle, run, days...  \n",
       "3     [battery, life, short, time, chargers, enough]  \n",
       "4  [battery, life, longer, 5, hours, due, battery...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_tokens'] = df['text'].apply(lambda x: nlp_pipeline(x))\n",
    "df['summary_tokens'] = df['summary'].apply(lambda x: nlp_pipeline(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START/END Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>summary_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>, and is very, very accurate .\\r\\n but for the...</td>\n",
       "      <td>This unit is generally quite accurate.  \\r\\nSe...</td>\n",
       "      <td>[&lt;START&gt;, accurate, part, find, garmin, softwa...</td>\n",
       "      <td>[&lt;START&gt;, unit, generally, quite, accurate, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>The room was not overly big, but clean and ve...</td>\n",
       "      <td>The rooms were not large but were clean and ve...</td>\n",
       "      <td>[&lt;START&gt;, room, overly, big, clean, comfortabl...</td>\n",
       "      <td>[&lt;START&gt;, rooms, large, clean, comfortable, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>After I plugged it in to my USB hub on my com...</td>\n",
       "      <td>Battery life is exceptional.\\r\\nThe Kindle can...</td>\n",
       "      <td>[&lt;START&gt;, plugged, usb, hub, computer, charge,...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, exceptional, kindle, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>short battery life  I moved up from an 8gb .\\...</td>\n",
       "      <td>The battery life is too short.\\r\\nThe time bet...</td>\n",
       "      <td>[&lt;START&gt;, short, battery, life, moved, 8gb, lo...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, short, time, chargers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...</td>\n",
       "      <td>The battery life is longer then 5 hours.\\r\\nBu...</td>\n",
       "      <td>[&lt;START&gt;, 6ghz, 533fsb, cpu, glossy, display, ...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, longer, 5, hours, due...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                                text  \\\n",
       "0  , and is very, very accurate .\\r\\n but for the...   \n",
       "1   The room was not overly big, but clean and ve...   \n",
       "2   After I plugged it in to my USB hub on my com...   \n",
       "3   short battery life  I moved up from an 8gb .\\...   \n",
       "4  6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This unit is generally quite accurate.  \\r\\nSe...   \n",
       "1  The rooms were not large but were clean and ve...   \n",
       "2  Battery life is exceptional.\\r\\nThe Kindle can...   \n",
       "3  The battery life is too short.\\r\\nThe time bet...   \n",
       "4  The battery life is longer then 5 hours.\\r\\nBu...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [<START>, accurate, part, find, garmin, softwa...   \n",
       "1  [<START>, room, overly, big, clean, comfortabl...   \n",
       "2  [<START>, plugged, usb, hub, computer, charge,...   \n",
       "3  [<START>, short, battery, life, moved, 8gb, lo...   \n",
       "4  [<START>, 6ghz, 533fsb, cpu, glossy, display, ...   \n",
       "\n",
       "                                      summary_tokens  \n",
       "0  [<START>, unit, generally, quite, accurate, se...  \n",
       "1  [<START>, rooms, large, clean, comfortable, ba...  \n",
       "2  [<START>, battery, life, exceptional, kindle, ...  \n",
       "3  [<START>, battery, life, short, time, chargers...  \n",
       "4  [<START>, battery, life, longer, 5, hours, due...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_start_end(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text_tokens'].values\n",
    "summaries = df['summary_tokens'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, word_to_id, id_to_word = create_vocabulary(np.concatenate((texts, summaries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>summary_tokens</th>\n",
       "      <th>text_indices</th>\n",
       "      <th>summary_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>, and is very, very accurate .\\r\\n but for the...</td>\n",
       "      <td>This unit is generally quite accurate.  \\r\\nSe...</td>\n",
       "      <td>[&lt;START&gt;, accurate, part, find, garmin, softwa...</td>\n",
       "      <td>[&lt;START&gt;, unit, generally, quite, accurate, se...</td>\n",
       "      <td>[440, 2649, 2035, 4156, 3937, 5707, 5747, 2649...</td>\n",
       "      <td>[440, 6079, 1713, 6056, 2649, 6617, 2629, 2610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>The room was not overly big, but clean and ve...</td>\n",
       "      <td>The rooms were not large but were clean and ve...</td>\n",
       "      <td>[&lt;START&gt;, room, overly, big, clean, comfortabl...</td>\n",
       "      <td>[&lt;START&gt;, rooms, large, clean, comfortable, ba...</td>\n",
       "      <td>[440, 984, 2141, 4129, 872, 684, 3121, 3724, 1...</td>\n",
       "      <td>[440, 3524, 1160, 872, 684, 88, 4908, 1176, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>After I plugged it in to my USB hub on my com...</td>\n",
       "      <td>Battery life is exceptional.\\r\\nThe Kindle can...</td>\n",
       "      <td>[&lt;START&gt;, plugged, usb, hub, computer, charge,...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, exceptional, kindle, ...</td>\n",
       "      <td>[440, 3183, 4169, 5482, 1609, 127, 3752, 5950,...</td>\n",
       "      <td>[440, 3752, 901, 3319, 3261, 7008, 3344, 727, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>short battery life  I moved up from an 8gb .\\...</td>\n",
       "      <td>The battery life is too short.\\r\\nThe time bet...</td>\n",
       "      <td>[&lt;START&gt;, short, battery, life, moved, 8gb, lo...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, short, time, chargers...</td>\n",
       "      <td>[440, 6839, 3752, 901, 3924, 6798, 1625, 2525,...</td>\n",
       "      <td>[440, 3752, 901, 6839, 6001, 1242, 3001, 6289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...</td>\n",
       "      <td>The battery life is longer then 5 hours.\\r\\nBu...</td>\n",
       "      <td>[&lt;START&gt;, 6ghz, 533fsb, cpu, glossy, display, ...</td>\n",
       "      <td>[&lt;START&gt;, battery, life, longer, 5, hours, due...</td>\n",
       "      <td>[440, 320, 3070, 5356, 4886, 3069, 6961, 2506,...</td>\n",
       "      <td>[440, 3752, 901, 154, 5005, 391, 5779, 3752, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "3      battery-life_ipod_nano_8gb   \n",
       "4     battery-life_netbook_1005ha   \n",
       "\n",
       "                                                text  \\\n",
       "0  , and is very, very accurate .\\r\\n but for the...   \n",
       "1   The room was not overly big, but clean and ve...   \n",
       "2   After I plugged it in to my USB hub on my com...   \n",
       "3   short battery life  I moved up from an 8gb .\\...   \n",
       "4  6GHz 533FSB cpu, glossy display, 3, Cell 23Wh ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This unit is generally quite accurate.  \\r\\nSe...   \n",
       "1  The rooms were not large but were clean and ve...   \n",
       "2  Battery life is exceptional.\\r\\nThe Kindle can...   \n",
       "3  The battery life is too short.\\r\\nThe time bet...   \n",
       "4  The battery life is longer then 5 hours.\\r\\nBu...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [<START>, accurate, part, find, garmin, softwa...   \n",
       "1  [<START>, room, overly, big, clean, comfortabl...   \n",
       "2  [<START>, plugged, usb, hub, computer, charge,...   \n",
       "3  [<START>, short, battery, life, moved, 8gb, lo...   \n",
       "4  [<START>, 6ghz, 533fsb, cpu, glossy, display, ...   \n",
       "\n",
       "                                      summary_tokens  \\\n",
       "0  [<START>, unit, generally, quite, accurate, se...   \n",
       "1  [<START>, rooms, large, clean, comfortable, ba...   \n",
       "2  [<START>, battery, life, exceptional, kindle, ...   \n",
       "3  [<START>, battery, life, short, time, chargers...   \n",
       "4  [<START>, battery, life, longer, 5, hours, due...   \n",
       "\n",
       "                                        text_indices  \\\n",
       "0  [440, 2649, 2035, 4156, 3937, 5707, 5747, 2649...   \n",
       "1  [440, 984, 2141, 4129, 872, 684, 3121, 3724, 1...   \n",
       "2  [440, 3183, 4169, 5482, 1609, 127, 3752, 5950,...   \n",
       "3  [440, 6839, 3752, 901, 3924, 6798, 1625, 2525,...   \n",
       "4  [440, 320, 3070, 5356, 4886, 3069, 6961, 2506,...   \n",
       "\n",
       "                                     summary_indices  \n",
       "0  [440, 6079, 1713, 6056, 2649, 6617, 2629, 2610...  \n",
       "1  [440, 3524, 1160, 872, 684, 88, 4908, 1176, 17...  \n",
       "2  [440, 3752, 901, 3319, 3261, 7008, 3344, 727, ...  \n",
       "3     [440, 3752, 901, 6839, 6001, 1242, 3001, 6289]  \n",
       "4  [440, 3752, 901, 154, 5005, 391, 5779, 3752, 6...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_indices'] = df['text_tokens'].apply(lambda tokens: np.array([word_to_id[word] for word in tokens]))\n",
    "df['summary_indices'] = df['summary_tokens'].apply(lambda tokens: np.array([word_to_id[word] for word in tokens]))\n",
    "\n",
    "text_indices = df['text_indices'].values\n",
    "summary_indices = df['summary_indices'].values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload pre-processed data as artifact to WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f0e7383cc40>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_data = wandb.Artifact(\n",
    "    \"opinosis-preprocessed\", type=\"dataset\",\n",
    "    description=\"Preprocessed OPINOSIS dataset\",\n",
    "    metadata={\"sizes\": len(df), \"pipeline\": [\"tokenization\", \"indexing\", \"start/end tokens\"]}\n",
    ")\n",
    "\n",
    "pre_processed_dataframe = wandb.Table(data=df, columns=df.columns, allow_mixed_types=True)\n",
    "pre_processed_data.add(pre_processed_dataframe, \"Preprocessed dataset\")\n",
    "run.log_artifact(pre_processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_embeddings(vocabulary,embedding_size=50, embedding_type='glove', dump_path='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_summaries, test_texts, test_summaries = train_test_split(text_indices, summary_indices, test_size=0.1)\n",
    "input_texts, input_summaries, next_words = create_train_data(train_texts, train_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_texts_length = max([len(text) for text in input_texts])\n",
    "max_summaries_length = max([len(summary) for summary in input_summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_texts = pad_sequences(input_texts, maxlen=max_texts_length)\n",
    "padded_summaries = pad_sequences(input_summaries, maxlen=max_summaries_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(list(word_to_id.values()))\n",
    "next_words = label_binarizer.transform(next_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "\n",
    "This section serves as demonstration of how to create a model. It is not necessary to create a model to run the experiment. Model training will be executed on my of my GPU servers, so there will be model imports from files.\n",
    "\n",
    "**Disclaimer:** Skip this section if you are running this notebook on low-end device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from scripts.model import create_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 06:38:21.879507: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-10 06:38:23,565 [ERROR] Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandar/envs/nlp-2021-n/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maleksandar1932\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/aleksandar/envs/nlp-2021-n/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2021-12-10 06:38:25.563570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 06:38:25.563620: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_3/runs/1zugfw7b\" target=\"_blank\">Encoder-Decoder-2d1474e3-60b1-43e0-9c8b-50a4b25ef11f</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder-Decoder-2d1474e3-60b1-43e0-9c8b-50a4b25ef11f\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 3674)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, 1619)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 3674, 50)     359400      ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1619, 50)     359400      ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder (LSTM)                 [(None, 128),        91648       ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " decoder (LSTM)                 [(None, 128),        91648       ['embedding_1[0][0]',            \n",
      "                                 (None, 128),                     'encoder[1][1]',                \n",
      "                                 (None, 128)]                     'encoder[1][2]']                \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, 7188)         927252      ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,829,348\n",
      "Trainable params: 1,110,548\n",
      "Non-trainable params: 718,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model = create_model(max_texts_length, max_summaries_length, len(vocabulary), 50, embeddings)\n",
    "model.compile(optimizer=Adam(lr=0.01), loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/90 [==============================] - 475s 5s/step - loss: 7.6703 - accuracy: 0.0327\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 467s 5s/step - loss: 6.5605 - accuracy: 0.0777\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 471s 5s/step - loss: 5.7146 - accuracy: 0.1091\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 514s 6s/step - loss: 4.6429 - accuracy: 0.1526\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 508s 6s/step - loss: 3.4564 - accuracy: 0.2939\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 468s 5s/step - loss: 2.3618 - accuracy: 0.4958\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 471s 5s/step - loss: 1.5743 - accuracy: 0.6649\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 471s 5s/step - loss: 1.0227 - accuracy: 0.7897\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 469s 5s/step - loss: 0.6632 - accuracy: 0.8749\n",
      "Epoch 10/15\n",
      " 4/90 [>.............................] - ETA: 7:50 - loss: 0.3752 - accuracy: 0.9570"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_510/3909814328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit([np.array(padded_texts), np.array(padded_summaries)],\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               batch_size=64, epochs=15, verbose=1, callbacks=[WandbCallback()])\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/nlp-2021-n/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([np.array(padded_texts), np.array(padded_summaries)],\n",
    "              np.array(next_words),\n",
    "              batch_size=64, epochs=15, verbose=1, callbacks=[WandbCallback()])\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fd9fc208b20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 622... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.87487</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.66317</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">Encoder-Decoder-2d1474e3-60b1-43e0-9c8b-50a4b25ef11f</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_3/runs/1zugfw7b\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_3/runs/1zugfw7b</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211210_063824-1zugfw7b/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Test Data\n",
    "\n",
    "For this example, the above model was pre-trained on CUDA enabled hardware, and it's going to be imported from a `/models` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 23:41:20.065953: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2021-12-10 23:41:20.066139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (legion-y540): /proc/driver/nvidia/version does not exist\n",
      "2021-12-10 23:41:20.066421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/opinosis_model-33f8c698-7ca7-4d28-b897-71b8677185a9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder-Decoder-5853b83a-2923-44aa-8ba1-103074a5a4b3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 3516)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, 2450)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 3516, 50)     359400      ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 2450, 50)     359400      ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder (LSTM)                 [(None, 128),        91648       ['embedding_4[0][0]']            \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " decoder (LSTM)                 [(None, 128),        91648       ['embedding_5[0][0]',            \n",
      "                                 (None, 128),                     'encoder[0][1]',                \n",
      "                                 (None, 128)]                     'encoder[0][2]']                \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, 7188)         927252      ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,829,348\n",
      "Trainable params: 1,110,548\n",
      "Non-trainable params: 718,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model import decode\n",
    "\n",
    "\n",
    "def decode(model, input_sent, word_to_id, padding_size, verbose=False):\n",
    "    generated_sentence = []\n",
    "    generated_sentence.append(word_to_id['<START>'])\n",
    "\n",
    "    for i in range(padding_size):\n",
    "        output_sent = pad_sequences([generated_sentence], padding_size)\n",
    "        predictions = model.predict(\n",
    "            [np.expand_dims(input_sent, axis=0), output_sent])\n",
    "        next_word = np.argmax(predictions)\n",
    "        if verbose:\n",
    "            print(next_word)\n",
    "        generated_sentence.append(next_word)\n",
    "\n",
    "    return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_texts_test = pad_sequences(test_texts, maxlen=3516)\n",
    "padded_summaries_test = pad_sequences(test_summaries, maxlen=max_summaries_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'5255'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_503/3410792637.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_texts_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3516\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_503/1511343022.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, input_sent, word_to_id, padding_size, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnext_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{word_to_id[str(next_word)]}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mgenerated_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '5255'"
     ]
    }
   ],
   "source": [
    "decode(model, padded_texts_test[0], word_to_id, 3516, True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d0b1b3f612c4c5e51656c8d0ea12cc8bdc13c9ac193c394dc1e17c8d0fd734"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp-2021-n': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
