{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "from scripts.word_embeddings import load_embedding_weights\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, words, vectors, path='.'):\n",
    "    with open(f'{path}/{name}.txt', 'w+', encoding='utf-8') as doc:\n",
    "        for word, vector in zip(words, vectors):\n",
    "            doc.write(word + ' ' + ' '.join(str(value) for value in vector))\n",
    "            doc.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not now, dad. We should burn Jon Snow. stop it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there may have been a mixcommunication with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i shouldn't have sold my boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like, It was my fault i made him mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>find a picture of 4 girls together on FB make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0    28.jpg           0        0           0                0         0   \n",
       "1    30.jpg           0        0           0                0         0   \n",
       "2    33.jpg           0        0           0                0         0   \n",
       "3    58.jpg           1        0           0                0         1   \n",
       "4    89.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  text_transcription  \n",
       "0  not now, dad. We should burn Jon Snow. stop it...  \n",
       "1  there may have been a mixcommunication with th...  \n",
       "2                      i shouldn't have sold my boat  \n",
       "3    Bitches be like, It was my fault i made him mad  \n",
       "4  find a picture of 4 girls together on FB make ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/trial.csv',delimiter=\"\t\")\n",
    "df.columns = ['file_name', 'misogynous', 'shaming', 'stereotype', 'objectification', 'violence', 'text_transcription']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text_transcription</th>\n",
       "      <th>text_transcription_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not now, dad. We should burn Jon Snow. stop it...</td>\n",
       "      <td>[dad, burn, jon, snow, stop, dad, know, happen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there may have been a mixcommunication with th...</td>\n",
       "      <td>[may, mixcommunication, decorator, happy, birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i shouldn't have sold my boat</td>\n",
       "      <td>[n't, sold, boat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like, It was my fault i made him mad</td>\n",
       "      <td>[bitches, like, fault, made, mad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>find a picture of 4 girls together on FB make ...</td>\n",
       "      <td>[find, picture, 4, girls, together, fb, make, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0    28.jpg           0        0           0                0         0   \n",
       "1    30.jpg           0        0           0                0         0   \n",
       "2    33.jpg           0        0           0                0         0   \n",
       "3    58.jpg           1        0           0                0         1   \n",
       "4    89.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  text_transcription  \\\n",
       "0  not now, dad. We should burn Jon Snow. stop it...   \n",
       "1  there may have been a mixcommunication with th...   \n",
       "2                      i shouldn't have sold my boat   \n",
       "3    Bitches be like, It was my fault i made him mad   \n",
       "4  find a picture of 4 girls together on FB make ...   \n",
       "\n",
       "                           text_transcription_tokens  \n",
       "0  [dad, burn, jon, snow, stop, dad, know, happen...  \n",
       "1  [may, mixcommunication, decorator, happy, birt...  \n",
       "2                                  [n't, sold, boat]  \n",
       "3                  [bitches, like, fault, made, mad]  \n",
       "4  [find, picture, 4, girls, together, fb, make, ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def remove_punctuation(token:str)->str:\n",
    "    punctuation_regex = '!\"#$&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    return ' '.join(word.strip(punctuation_regex) for word in token.split())\n",
    "\n",
    "def nlp_pipeline(token:str) -> str:\n",
    "    token = remove_punctuation(token)\n",
    "    tokens = word_tokenize(token.lower())\n",
    "    tokens = [token for token in tokens if token not in ENGLISH_STOPWORDS]\n",
    "    return tokens\n",
    "\n",
    "df['text_transcription_tokens'] = df['text_transcription'].apply(lambda x: nlp_pipeline(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text_transcription_tokens'].values\n",
    "\n",
    "def build_embeddings(model_name, sentences, size, path):\n",
    "    if model_name == 'word2vec':\n",
    "        model = Word2Vec(sentences, vector_size=size, min_count=1, window=5, sg=1)\n",
    "        vectors = model.wv.vectors      \n",
    "        words = model.wv.index_to_key\n",
    "\n",
    "        save(f'{model_name}SG.iSarcasamEval.{size}d', words, vectors,path=path)\n",
    "\n",
    "for size in [10, 50, 100]:\n",
    "    build_embeddings('word2vec', sentences, size=size, path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text_transcription_tokens'].values\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(tokenizer.word_index.keys()))\n",
    "vocabulary_size = len(tokenizer.word_index)\n",
    "max_length = max(map(lambda x: len(x), tokenizer.word_index.keys()))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(sentences)\n",
    "X_pad = pad_sequences(X, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['misogynous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {\n",
    "    10: load_embedding_weights(vocabulary, 10, 'word2vecSG', \".\"),\n",
    "    50: load_embedding_weights(vocabulary, 50, 'word2vecSG', \".\"),\n",
    "    100: load_embedding_weights(vocabulary, 100, 'word2vecSG', \".\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding weights...\n"
     ]
    }
   ],
   "source": [
    "glove_50 = load_embedding_weights(vocabulary, 50, 'glove', \"/mnt/d/Downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without initialized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"withoutInitializedWeights\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 100)         47100     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, None, 100)         80400     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, None, 1)           101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127,601\n",
      "Trainable params: 127,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"withoutInitializedWeights\")\n",
    "model.add(Embedding(input_dim = vocabulary_size + 1, output_dim=100))\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:14obtoxe) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6598... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">withoutInitializedWeights</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/14obtoxe\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/14obtoxe</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211113_173156-14obtoxe/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:14obtoxe). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 17:32:23.992145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-13 17:32:23.992188: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/4k00y4cp\" target=\"_blank\">withoutInitializedWeights</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 52ms/step - loss: 0.6933 - accuracy: 0.5090\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.5919\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6652 - accuracy: 0.6584\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3178 - accuracy: 0.9442\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2090 - accuracy: 0.9625\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0677 - accuracy: 0.9845\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0244 - accuracy: 0.9959\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0237 - accuracy: 0.9966\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0186 - accuracy: 0.9976\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0134 - accuracy: 0.9976\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0101 - accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0064 - accuracy: 0.9976\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0057 - accuracy: 0.9976\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0054 - accuracy: 0.9976\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0052 - accuracy: 0.9972\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0051 - accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0049 - accuracy: 0.9976\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0048 - accuracy: 0.9976\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0047 - accuracy: 0.9976\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0046 - accuracy: 0.9976\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0045 - accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0044 - accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0043 - accuracy: 0.9979\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0043 - accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0042 - accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0042 - accuracy: 0.9976\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0041 - accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0040 - accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0040 - accuracy: 0.9976\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0039 - accuracy: 0.9979\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0039 - accuracy: 0.9979\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0038 - accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0038 - accuracy: 0.9976\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0037 - accuracy: 0.9972\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0037 - accuracy: 0.9979\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0035 - accuracy: 0.9976\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9972\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6781... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99759</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.00316</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">withoutInitializedWeights</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/4k00y4cp\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/4k00y4cp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211113_173217-4k00y4cp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=100, callbacks=[WandbCallback()])\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec.50d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, None, 100)         47100     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, None, 64)          42240     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, None, 128)         98816     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, None, 1)           129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,285\n",
      "Trainable params: 188,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"word2vec.50d\")\n",
    "\n",
    "model.add(Embedding(input_dim = vocabulary_size + 1, weights=[embeddings[100]], output_dim=100))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 17:31:28.069684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-13 17:31:28.069729: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ni054vf\" target=\"_blank\">word2vec.50d</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0033 - accuracy: 0.9976\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6420... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁██▅████████▅█████████████▄█▅██▅██▅███▅█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇█▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▃▄▄▄▃▃▂▄▄▃▂▁▂▂▂▂▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99828</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00301</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">word2vec.50d</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ni054vf\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ni054vf</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211113_173125-1ni054vf/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=50, callbacks=[WandbCallback()])\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove.50d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, None, 50)          23550     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, None, 128)         91648     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, None, 1)           129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,327\n",
      "Trainable params: 115,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"glove.50d\")\n",
    "\n",
    "model.add(Embedding(input_dim = vocabulary_size+1, output_dim=50))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.05), loss=binary_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 18:01:33.792602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-13 18:01:33.792646: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/xj33dxud\" target=\"_blank\">glove.50d</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0040 - accuracy: 0.9983\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0040 - accuracy: 0.9983\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0039 - accuracy: 0.9983\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0039 - accuracy: 0.9983\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0037 - accuracy: 0.9983\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0037 - accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0037 - accuracy: 0.9983\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0035 - accuracy: 0.9976\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0035 - accuracy: 0.9979\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0034 - accuracy: 0.9979\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9976\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9979\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0032 - accuracy: 0.9983\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0031 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0030 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7105... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>████████████▁█▄█▄▄██▅███▁▄▅▅██████████▄█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99828</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.00303</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glove.50d</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/xj33dxud\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/xj33dxud</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211113_180131-xj33dxud/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=50, callbacks=[WandbCallback()])\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WANDB was used to track the runs, all of the results are available at the [link](https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2?workspace=user-aleksandar1932)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d0b1b3f612c4c5e51656c8d0ea12cc8bdc13c9ac193c394dc1e17c8d0fd734"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp-2021-n': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
