{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:39:07.842452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:39:07.842495: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, words, vectors, path='.'):\n",
    "    with open(f'{path}/{name}.txt', 'w+', encoding='utf-8') as doc:\n",
    "        for word, vector in zip(words, vectors):\n",
    "            doc.write(word + ' ' + ' '.join(str(value) for value in vector))\n",
    "            doc.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_embeddings(file_name, vocabulary):\n",
    "    \"\"\"\n",
    "    Loads word embeddings from the file with the given name.\n",
    "    :param file_name: name of the file containing word embeddings\n",
    "    :type file_name: str\n",
    "    :param vocabulary: captions vocabulary\n",
    "    :type vocabulary: numpy.array\n",
    "    :return: word embeddings\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    embeddings = dict()\n",
    "    with open(file_name, 'r', encoding='utf-8') as doc:\n",
    "        line = doc.readline()\n",
    "        while line != '':\n",
    "            line = line.rstrip('\\n').lower()\n",
    "            parts = line.split(' ')\n",
    "            vals = np.array(parts[1:], dtype=np.float)\n",
    "            if parts[0] in vocabulary:\n",
    "                embeddings[parts[0]] = vals\n",
    "            line = doc.readline()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_embedding_weights(vocabulary, embedding_size, embedding_type, path='.'):\n",
    "    print(\"local\")\n",
    "    \"\"\"\n",
    "    Creates and loads embedding weights.\n",
    "    :param vocabulary: vocabulary\n",
    "    :type vocabulary: numpy.array\n",
    "    :param embedding_size: embedding size\n",
    "    :type embedding_size: int\n",
    "    :param embedding_type: type of the pre-trained embeddings\n",
    "    :type embedding_type: string\n",
    "    :return: embedding weights\n",
    "    :rtype: numpy.array\n",
    "    \"\"\"\n",
    "    if os.path.exists(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl'):\n",
    "        with open(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl', 'rb') as f:\n",
    "            embedding_matrix = pickle.load(f)\n",
    "    else:\n",
    "        print('Creating embedding weights...')\n",
    "        if embedding_type == 'glove':\n",
    "            embeddings = load_embeddings(f'{path}/glove.6B.{embedding_size}d.txt', vocabulary)\n",
    "        else:\n",
    "          embeddings = load_embeddings(f'{path}/word2vecSG.iSarcasamEval.{embedding_size}d.txt', vocabulary)\n",
    "        embedding_matrix = np.zeros((len(vocabulary), embedding_size))\n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in embeddings.keys():\n",
    "                embedding_matrix[i] = embeddings[vocabulary[i]]\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.standard_normal(embedding_size)\n",
    "        with open(f'{path}/embedding_matrix_{embedding_type}_{embedding_size}.pkl', 'wb') as f:\n",
    "            pickle.dump(embedding_matrix, f)\n",
    "    return embedding_matrix\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(sentence_tokens):\n",
    "    vocabulary = set()\n",
    "    for tokens in sentence_tokens:\n",
    "        vocabulary.update(tokens)\n",
    "\n",
    "    vocabulary = list(vocabulary)\n",
    "    word_to_id = {word: index for word, index in zip(vocabulary, range(len(vocabulary)))}\n",
    "    return vocabulary, word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not now, dad. We should burn Jon Snow. stop it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there may have been a mixcommunication with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i shouldn't have sold my boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like, It was my fault i made him mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>find a picture of 4 girls together on FB make ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0    28.jpg           0        0           0                0         0   \n",
       "1    30.jpg           0        0           0                0         0   \n",
       "2    33.jpg           0        0           0                0         0   \n",
       "3    58.jpg           1        0           0                0         1   \n",
       "4    89.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  text_transcription  \n",
       "0  not now, dad. We should burn Jon Snow. stop it...  \n",
       "1  there may have been a mixcommunication with th...  \n",
       "2                      i shouldn't have sold my boat  \n",
       "3    Bitches be like, It was my fault i made him mad  \n",
       "4  find a picture of 4 girls together on FB make ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/trial.csv',delimiter=\"\t\")\n",
    "df.columns = ['file_name', 'misogynous', 'shaming', 'stereotype', 'objectification', 'violence', 'text_transcription']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text_transcription</th>\n",
       "      <th>text_transcription_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not now, dad. We should burn Jon Snow. stop it...</td>\n",
       "      <td>[dad, burn, jon, snow, stop, dad, know, happen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there may have been a mixcommunication with th...</td>\n",
       "      <td>[may, mixcommunication, decorator, happy, birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i shouldn't have sold my boat</td>\n",
       "      <td>[n't, sold, boat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like, It was my fault i made him mad</td>\n",
       "      <td>[bitches, like, fault, made, mad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>find a picture of 4 girls together on FB make ...</td>\n",
       "      <td>[find, picture, 4, girls, together, fb, make, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0    28.jpg           0        0           0                0         0   \n",
       "1    30.jpg           0        0           0                0         0   \n",
       "2    33.jpg           0        0           0                0         0   \n",
       "3    58.jpg           1        0           0                0         1   \n",
       "4    89.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  text_transcription  \\\n",
       "0  not now, dad. We should burn Jon Snow. stop it...   \n",
       "1  there may have been a mixcommunication with th...   \n",
       "2                      i shouldn't have sold my boat   \n",
       "3    Bitches be like, It was my fault i made him mad   \n",
       "4  find a picture of 4 girls together on FB make ...   \n",
       "\n",
       "                           text_transcription_tokens  \n",
       "0  [dad, burn, jon, snow, stop, dad, know, happen...  \n",
       "1  [may, mixcommunication, decorator, happy, birt...  \n",
       "2                                  [n't, sold, boat]  \n",
       "3                  [bitches, like, fault, made, mad]  \n",
       "4  [find, picture, 4, girls, together, fb, make, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def remove_punctuation(token:str)->str:\n",
    "    punctuation_regex = '!\"#$&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    return ' '.join(word.strip(punctuation_regex) for word in token.split())\n",
    "\n",
    "def nlp_pipeline(token:str) -> str:\n",
    "    token = remove_punctuation(token)\n",
    "    tokens = word_tokenize(token.lower())\n",
    "    tokens = [token for token in tokens if token not in ENGLISH_STOPWORDS]\n",
    "    return tokens\n",
    "\n",
    "df['text_transcription_tokens'] = df['text_transcription'].apply(lambda x: nlp_pipeline(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text_transcription_tokens'].values\n",
    "\n",
    "def build_embeddings(model_name, sentences, size, path):\n",
    "    if model_name == 'word2vec':\n",
    "        model = Word2Vec(sentences, vector_size=size, min_count=1, window=5, sg=1)\n",
    "        vectors = model.wv.vectors      \n",
    "        words = model.wv.index_to_key\n",
    "\n",
    "        save(f'{model_name}SG.iSarcasamEval.{size}d', words, vectors,path=path)\n",
    "\n",
    "for size in [10, 50, 100]:\n",
    "    build_embeddings('word2vec', sentences, size=size, path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text_transcription_tokens'].values\n",
    "\n",
    "vocabulary, word_to_id = create_vocabulary(sentences)\n",
    "vocabulary_size = len(vocabulary)\n",
    "max_length = max(map(lambda x: len(x), word_to_id.keys()))\n",
    "X = df['text_transcription_tokens'].apply(lambda x: np.array([word_to_id[i] for i in x])).values\n",
    "\n",
    "X_pad = pad_sequences(X, maxlen=max_length, padding='post')\n",
    "y = df['misogynous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "embeddings = {\n",
    "    50: load_embedding_weights(vocabulary, 50, 'word2vecSG', \".\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "glove_50 = load_embedding_weights(vocabulary, 50, 'glove', \"/mnt/d/Downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without initialized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:39:31.099441: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:39:31.099482: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-14 21:39:31.099525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (legion-y540): /proc/driver/nvidia/version does not exist\n",
      "2021-11-14 21:39:31.099834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"without_initialized_weights.task1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         47000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 100)         80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 1)           101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127,501\n",
      "Trainable params: 127,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"without_initialized_weights.task1\")\n",
    "model.add(Embedding(input_dim = vocabulary_size, output_dim=100))\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01), loss=binary_crossentropy, metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maleksandar1932\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/aleksandar/envs/nlp-2021-n/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "2021-11-14 21:39:36.637687: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:39:36.637762: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2s6tbi7k\" target=\"_blank\">without_initialized_weights.task1</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 57ms/step - loss: 0.7015 - accuracy: 0.5306 - f1_m: 0.5752 - precision_m: 0.3789 - recall_m: 2.1349\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6911 - accuracy: 0.5523 - f1_m: 1.2321 - precision_m: 0.6472 - recall_m: 24.3691\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6420 - accuracy: 0.7121 - f1_m: 1.8009 - precision_m: 0.9679 - recall_m: 13.4485\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1950 - accuracy: 0.9831 - f1_m: 1.8869 - precision_m: 0.9713 - recall_m: 32.9257\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0376 - accuracy: 0.9948 - f1_m: 1.9201 - precision_m: 0.9889 - recall_m: 32.9722\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0180 - accuracy: 0.9966 - f1_m: 1.9289 - precision_m: 0.9935 - recall_m: 32.9778\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0104 - accuracy: 0.9969 - f1_m: 1.9310 - precision_m: 0.9946 - recall_m: 32.9466\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0071 - accuracy: 0.9972 - f1_m: 1.9354 - precision_m: 0.9970 - recall_m: 32.9125\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0055 - accuracy: 0.9976 - f1_m: 1.9361 - precision_m: 0.9974 - recall_m: 32.9132\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0046 - accuracy: 0.9979 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9216\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0041 - accuracy: 0.9979 - f1_m: 1.9356 - precision_m: 0.9971 - recall_m: 32.9211\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0038 - accuracy: 0.9976 - f1_m: 1.9369 - precision_m: 0.9978 - recall_m: 32.8984\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 0.9979 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.8883\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0033 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9986 - recall_m: 32.9156\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 0.9983 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9375\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0031 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9986 - recall_m: 32.9267\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0030 - accuracy: 0.9979 - f1_m: 1.9366 - precision_m: 0.9976 - recall_m: 32.9221\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0029 - accuracy: 0.9986 - f1_m: 1.9359 - precision_m: 0.9972 - recall_m: 32.9667\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0029 - accuracy: 0.9983 - f1_m: 1.9370 - precision_m: 0.9978 - recall_m: 32.9459\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 0.9979 - f1_m: 1.9370 - precision_m: 0.9979 - recall_m: 32.9351\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0028 - accuracy: 0.9986 - f1_m: 1.9386 - precision_m: 0.9987 - recall_m: 32.9556\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9535\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0027 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9421\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9985 - recall_m: 32.9484\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 0.9983 - f1_m: 1.9368 - precision_m: 0.9977 - recall_m: 32.9441\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9369 - precision_m: 0.9977 - recall_m: 32.9804\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 0.9983 - f1_m: 1.9374 - precision_m: 0.9980 - recall_m: 32.9501\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9535\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9360 - precision_m: 0.9973 - recall_m: 32.9556\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9368 - precision_m: 0.9977 - recall_m: 32.9489\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9985 - recall_m: 32.9521\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9356 - precision_m: 0.9971 - recall_m: 32.9582\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9352 - precision_m: 0.9969 - recall_m: 32.9697\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9979 - f1_m: 1.9361 - precision_m: 0.9974 - recall_m: 32.9132\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9399 - precision_m: 0.9994 - recall_m: 32.9222\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9397 - precision_m: 0.9993 - recall_m: 32.9251\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9393 - precision_m: 0.9991 - recall_m: 32.9244\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9398 - precision_m: 0.9994 - recall_m: 32.9156\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 0.9983 - f1_m: 1.9382 - precision_m: 0.9985 - recall_m: 32.9474\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9366 - precision_m: 0.9976 - recall_m: 32.9744\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9386 - precision_m: 0.9987 - recall_m: 32.9487\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9985 - recall_m: 32.9556\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9522\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9375 - precision_m: 0.9981 - recall_m: 32.9373\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9400 - precision_m: 0.9994 - recall_m: 32.9074\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9370\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9375 - precision_m: 0.9981 - recall_m: 32.9649\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9459\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9554\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9540\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9506\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9378 - precision_m: 0.9982 - recall_m: 32.9583\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9459\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9407\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9398 - precision_m: 0.9994 - recall_m: 32.9167\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9395 - precision_m: 0.9992 - recall_m: 32.9327\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 0.9983 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9302\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9379 - precision_m: 0.9983 - recall_m: 32.9608\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9376 - precision_m: 0.9981 - recall_m: 32.9596\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9985 - recall_m: 32.9489\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9407\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9463\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9506\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9398 - precision_m: 0.9993 - recall_m: 32.9278\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9395 - precision_m: 0.9992 - recall_m: 32.9352\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9429\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9985 - recall_m: 32.9441\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9458\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9630\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9983 - f1_m: 1.9368 - precision_m: 0.9977 - recall_m: 32.9583\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9370 - precision_m: 0.9978 - recall_m: 32.9762\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9366 - precision_m: 0.9976 - recall_m: 32.9762\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 0.9983 - f1_m: 1.9365 - precision_m: 0.9975 - recall_m: 32.9535\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9386 - precision_m: 0.9987 - recall_m: 32.9500\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9374 - precision_m: 0.9980 - recall_m: 32.9463\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9983 - recall_m: 32.9454\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9399 - precision_m: 0.9994 - recall_m: 32.9347\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9554\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9537\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9444\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9388 - precision_m: 0.9988 - recall_m: 32.9608\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9481\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9489\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 0.9983 - f1_m: 1.9372 - precision_m: 0.9980 - recall_m: 32.9233\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9548\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9548\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9983 - f1_m: 1.9379 - precision_m: 0.9983 - recall_m: 32.9248\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9398 - precision_m: 0.9993 - recall_m: 32.9333\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9986 - recall_m: 32.9249\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 0.9983 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9265\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9393 - precision_m: 0.9991 - recall_m: 32.9218\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 0.9986 - f1_m: 1.9393 - precision_m: 0.9991 - recall_m: 32.9412\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9397 - precision_m: 0.9993 - recall_m: 32.9286\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9392 - precision_m: 0.9990 - recall_m: 32.9302\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9392 - precision_m: 0.9990 - recall_m: 32.9370\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9506\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9583\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9359 - precision_m: 0.9972 - recall_m: 32.9667\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 0.9986 - f1_m: 1.9369 - precision_m: 0.9977 - recall_m: 32.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d44353af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=100, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.9088\n",
      "Test accuracy: 0.5030\n",
      "Test f1_score: 0.6600\n",
      "Test precision: 0.3350\n",
      "Test recall: 22.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2330... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄██████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>loss</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision_m</td><td>▁███████████████████████████████████████</td></tr><tr><td>recall_m</td><td>▁▄██████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99862</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1_m</td><td>1.93687</td></tr><tr><td>loss</td><td>0.00219</td></tr><tr><td>precision_m</td><td>0.99773</td></tr><tr><td>recall_m</td><td>32.97917</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">without_initialized_weights.task1</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2s6tbi7k\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2s6tbi7k</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_213935-2s6tbi7k/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec.50d.task1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          23500     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 64)          29440     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 128)         98816     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 1)           129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,885\n",
      "Trainable params: 151,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"word2vec.50d.task1\")\n",
    "\n",
    "model.add(Embedding(input_dim = vocabulary_size, weights=[embeddings[50]], output_dim=50))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01), loss=binary_crossentropy, metrics=['accuracy', f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:40:39.145566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:40:39.145613: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1fegfe2p\" target=\"_blank\">word2vec.50d.task1</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 3s 83ms/step - loss: 0.7005 - accuracy: 0.5010 - f1_m: 0.5923 - precision_m: 0.3034 - recall_m: 13.7468\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6955 - accuracy: 0.5145 - f1_m: 0.2767 - precision_m: 0.1429 - recall_m: 4.3846\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.6757 - accuracy: 0.5937 - f1_m: 0.6268 - precision_m: 0.3333 - recall_m: 5.2424\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3176 - accuracy: 0.9322 - f1_m: 1.8300 - precision_m: 0.9437 - recall_m: 30.1557\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0984 - accuracy: 0.9769 - f1_m: 1.9083 - precision_m: 0.9839 - recall_m: 31.6174\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0329 - accuracy: 0.9962 - f1_m: 1.9365 - precision_m: 0.9977 - recall_m: 32.8125\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0198 - accuracy: 0.9972 - f1_m: 1.9365 - precision_m: 0.9976 - recall_m: 32.8750\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0134 - accuracy: 0.9976 - f1_m: 1.9352 - precision_m: 0.9969 - recall_m: 32.9400\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0097 - accuracy: 0.9972 - f1_m: 1.9342 - precision_m: 0.9963 - recall_m: 32.9306\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0074 - accuracy: 0.9979 - f1_m: 1.9370 - precision_m: 0.9979 - recall_m: 32.9412\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0060 - accuracy: 0.9979 - f1_m: 1.9352 - precision_m: 0.9969 - recall_m: 32.9524\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0051 - accuracy: 0.9976 - f1_m: 1.9334 - precision_m: 0.9959 - recall_m: 32.9419\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0044 - accuracy: 0.9976 - f1_m: 1.9341 - precision_m: 0.9963 - recall_m: 32.9583\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0040 - accuracy: 0.9979 - f1_m: 1.9343 - precision_m: 0.9964 - recall_m: 32.9778\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0037 - accuracy: 0.9979 - f1_m: 1.9337 - precision_m: 0.9961 - recall_m: 32.9792\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0035 - accuracy: 0.9979 - f1_m: 1.9343 - precision_m: 0.9964 - recall_m: 32.9722\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0033 - accuracy: 0.9983 - f1_m: 1.9356 - precision_m: 0.9970 - recall_m: 32.9762\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0032 - accuracy: 0.9983 - f1_m: 1.9373 - precision_m: 0.9980 - recall_m: 32.9392\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0030 - accuracy: 0.9986 - f1_m: 1.9378 - precision_m: 0.9982 - recall_m: 32.9421\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9986 - f1_m: 1.9375 - precision_m: 0.9981 - recall_m: 32.9167\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0028 - accuracy: 0.9986 - f1_m: 1.9374 - precision_m: 0.9980 - recall_m: 32.9792\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - accuracy: 0.9986 - f1_m: 1.9386 - precision_m: 0.9987 - recall_m: 32.9475\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0028 - accuracy: 0.9986 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9410\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0027 - accuracy: 0.9986 - f1_m: 1.9373 - precision_m: 0.9980 - recall_m: 32.9630\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0027 - accuracy: 0.9983 - f1_m: 1.9385 - precision_m: 0.9987 - recall_m: 32.9253\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9209\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9377 - precision_m: 0.9982 - recall_m: 32.9593\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9315\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9400 - precision_m: 0.9994 - recall_m: 32.9444\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9396 - precision_m: 0.9992 - recall_m: 32.9225\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0025 - accuracy: 0.9983 - f1_m: 1.9381 - precision_m: 0.9984 - recall_m: 32.9317\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0026 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9569\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9526\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0025 - accuracy: 0.9983 - f1_m: 1.9378 - precision_m: 0.9983 - recall_m: 32.9275\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9393 - precision_m: 0.9991 - recall_m: 32.9198\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9985 - recall_m: 32.9258\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9444\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9986 - recall_m: 32.9394\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0026 - accuracy: 0.9983 - f1_m: 1.9354 - precision_m: 0.9970 - recall_m: 32.9444\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9367 - precision_m: 0.9976 - recall_m: 32.9825\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0024 - accuracy: 0.9983 - f1_m: 1.9359 - precision_m: 0.9973 - recall_m: 32.9394\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9379 - precision_m: 0.9983 - recall_m: 32.9444\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0025 - accuracy: 0.9986 - f1_m: 1.9376 - precision_m: 0.9982 - recall_m: 32.9419\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0025 - accuracy: 0.9983 - f1_m: 1.9376 - precision_m: 0.9982 - recall_m: 32.9474\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9379 - precision_m: 0.9983 - recall_m: 32.9512\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9385 - precision_m: 0.9987 - recall_m: 32.9444\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9444\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0024 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9986 - recall_m: 32.9222\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0024 - accuracy: 0.9983 - f1_m: 1.9383 - precision_m: 0.9986 - recall_m: 32.9262\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0024 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca5cd3550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=50, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.2160\n",
      "Test accuracy: 0.5697\n",
      "Test f1_score: 0.7051\n",
      "Test precision: 0.3595\n",
      "Test recall: 18.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2457... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▂▇████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▂▁▂█████████████████████████████████████</td></tr><tr><td>loss</td><td>███▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision_m</td><td>▂▁▃█████████████████████████████████████</td></tr><tr><td>recall_m</td><td>▃▁▁▇████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99862</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>f1_m</td><td>1.93869</td></tr><tr><td>loss</td><td>0.00237</td></tr><tr><td>precision_m</td><td>0.99873</td></tr><tr><td>recall_m</td><td>32.94074</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">word2vec.50d.task1</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1fegfe2p\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1fegfe2p</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_214037-1fegfe2p/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove.50d.task1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 50)          23500     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 128)         91648     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 1)           129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,277\n",
      "Trainable params: 115,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"glove.50d.task1\")\n",
    "\n",
    "model.add(Embedding(input_dim = vocabulary_size, output_dim=50))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.05), loss=binary_crossentropy, metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:41:16.595611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:41:16.595653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2x6msfu1\" target=\"_blank\">glove.50d.task1</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 48ms/step - loss: 0.8331 - accuracy: 0.5165 - f1_m: 0.6226 - precision_m: 0.3173 - recall_m: 16.5152\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8549 - accuracy: 0.4742 - f1_m: 0.7736 - precision_m: 0.6357 - recall_m: 10.2955\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7788 - accuracy: 0.4666 - f1_m: 0.8822 - precision_m: 0.4479 - recall_m: 32.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7365 - accuracy: 0.5372 - f1_m: 0.6617 - precision_m: 0.5347 - recall_m: 0.8693\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7389 - accuracy: 0.5155 - f1_m: 0.6907 - precision_m: 0.4838 - recall_m: 11.3758\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7595 - accuracy: 0.4762 - f1_m: 0.9131 - precision_m: 0.4632 - recall_m: 32.9206\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8280 - accuracy: 0.5403 - f1_m: 0.6991 - precision_m: 0.6964 - recall_m: 0.8758\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7521 - accuracy: 0.4993 - f1_m: 0.8462 - precision_m: 0.6452 - recall_m: 11.6947\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7584 - accuracy: 0.4738 - f1_m: 0.9111 - precision_m: 0.4621 - recall_m: 32.9804\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.7009 - accuracy: 0.5775 - f1_m: 1.0391 - precision_m: 0.7447 - recall_m: 4.1840\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6579 - accuracy: 0.5486 - f1_m: 0.9504 - precision_m: 0.7589 - recall_m: 1.3659\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6624 - accuracy: 0.5430 - f1_m: 0.9836 - precision_m: 0.5002 - recall_m: 31.6000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5716 - accuracy: 0.7252 - f1_m: 1.4504 - precision_m: 0.7518 - recall_m: 25.6722\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5667 - accuracy: 0.6326 - f1_m: 1.4342 - precision_m: 0.9090 - recall_m: 9.2431\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4810 - accuracy: 0.9001 - f1_m: 1.7956 - precision_m: 0.9274 - recall_m: 29.5439\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.4499 - accuracy: 0.9442 - f1_m: 1.7314 - precision_m: 0.8894 - recall_m: 32.9667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3956 - accuracy: 0.8147 - f1_m: 1.8655 - precision_m: 0.9771 - recall_m: 20.5746\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3756 - accuracy: 0.8061 - f1_m: 1.8035 - precision_m: 0.9437 - recall_m: 20.5038\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3541 - accuracy: 0.9549 - f1_m: 1.7236 - precision_m: 0.8856 - recall_m: 32.8678\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3300 - accuracy: 0.8922 - f1_m: 1.8085 - precision_m: 0.9391 - recall_m: 27.5501\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2957 - accuracy: 0.8543 - f1_m: 1.8160 - precision_m: 0.9445 - recall_m: 25.2609\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2574 - accuracy: 0.9707 - f1_m: 1.8351 - precision_m: 0.9438 - recall_m: 32.9400\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2114 - accuracy: 0.9817 - f1_m: 1.8757 - precision_m: 0.9654 - recall_m: 32.9167\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1540 - accuracy: 0.9828 - f1_m: 1.8653 - precision_m: 0.9599 - recall_m: 32.9558\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1282 - accuracy: 0.9835 - f1_m: 1.8728 - precision_m: 0.9639 - recall_m: 32.9172\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1017 - accuracy: 0.9852 - f1_m: 1.8736 - precision_m: 0.9643 - recall_m: 32.9583\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0787 - accuracy: 0.9866 - f1_m: 1.8759 - precision_m: 0.9655 - recall_m: 32.9833\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0569 - accuracy: 0.9866 - f1_m: 1.8963 - precision_m: 0.9763 - recall_m: 32.9434\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0377 - accuracy: 0.9921 - f1_m: 1.9163 - precision_m: 0.9868 - recall_m: 32.9619\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0304 - accuracy: 0.9979 - f1_m: 1.9360 - precision_m: 0.9973 - recall_m: 32.9117\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0189 - accuracy: 0.9979 - f1_m: 1.9369 - precision_m: 0.9978 - recall_m: 32.9222\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0183 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9526\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0146 - accuracy: 0.9986 - f1_m: 1.9390 - precision_m: 0.9989 - recall_m: 32.9606\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0107 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9466\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0090 - accuracy: 0.9986 - f1_m: 1.9376 - precision_m: 0.9982 - recall_m: 32.9489\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0082 - accuracy: 0.9986 - f1_m: 1.9373 - precision_m: 0.9980 - recall_m: 32.9566\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0078 - accuracy: 0.9986 - f1_m: 1.9373 - precision_m: 0.9980 - recall_m: 32.9444\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0073 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9524\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0069 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9984 - recall_m: 32.9521\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0066 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9566\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0063 - accuracy: 0.9986 - f1_m: 1.9373 - precision_m: 0.9980 - recall_m: 32.9410\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0061 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9985 - recall_m: 32.9556\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0059 - accuracy: 0.9986 - f1_m: 1.9376 - precision_m: 0.9982 - recall_m: 32.9394\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0057 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9535\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0055 - accuracy: 0.9986 - f1_m: 1.9382 - precision_m: 0.9984 - recall_m: 32.9556\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0053 - accuracy: 0.9986 - f1_m: 1.9380 - precision_m: 0.9984 - recall_m: 32.9514\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0051 - accuracy: 0.9986 - f1_m: 1.9387 - precision_m: 0.9987 - recall_m: 32.9339\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0047 - accuracy: 0.9986 - f1_m: 1.9384 - precision_m: 0.9986 - recall_m: 32.9444\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0044 - accuracy: 0.9986 - f1_m: 1.9398 - precision_m: 0.9993 - recall_m: 32.9253\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0041 - accuracy: 0.9986 - f1_m: 1.9400 - precision_m: 0.9994 - recall_m: 32.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca5b8c4c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=50, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.0158\n",
      "Test accuracy: 0.4727\n",
      "Test f1_score: 0.7174\n",
      "Test precision: 0.3626\n",
      "Test recall: 33.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2571... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▂▁▁▂▁▂▁▁▂▂▄▃▇▆▅▇▆███████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▁▂▂▁▃▁▂▃▃▃▅▅▇█▇▇▇▇██████████████████████</td></tr><tr><td>loss</td><td>██▇▇▇█▇▇▆▆▆▆▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>precision_m</td><td>▁▄▂▃▂▅▄▂▆▃▅▇▇█▇▇▇▇██████████████████████</td></tr><tr><td>recall_m</td><td>▄▃█▁█▁▃█▁█▆▃█▅▅█▆███████████████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99862</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>f1_m</td><td>1.94001</td></tr><tr><td>loss</td><td>0.00415</td></tr><tr><td>precision_m</td><td>0.99944</td></tr><tr><td>recall_m</td><td>32.93704</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">glove.50d.task1</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2x6msfu1\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/2x6msfu1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_214115-2x6msfu1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WANDB was used to track the training process along with the evaluation, all of the results are available at the [link](https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2?workspace=user-aleksandar1932).\n",
    "\n",
    "*Runs are postfixed with `.task1`*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text_transcription</th>\n",
       "      <th>text_transcription_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>not now, dad. We should burn Jon Snow. stop it...</td>\n",
       "      <td>[dad, burn, jon, snow, stop, dad, know, happen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there may have been a mixcommunication with th...</td>\n",
       "      <td>[may, mixcommunication, decorator, happy, birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i shouldn't have sold my boat</td>\n",
       "      <td>[n't, sold, boat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitches be like, It was my fault i made him mad</td>\n",
       "      <td>[bitches, like, fault, made, mad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>find a picture of 4 girls together on FB make ...</td>\n",
       "      <td>[find, picture, 4, girls, together, fb, make, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0    28.jpg           0        0           0                0         0   \n",
       "1    30.jpg           0        0           0                0         0   \n",
       "2    33.jpg           0        0           0                0         0   \n",
       "3    58.jpg           1        0           0                0         1   \n",
       "4    89.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  text_transcription  \\\n",
       "0  not now, dad. We should burn Jon Snow. stop it...   \n",
       "1  there may have been a mixcommunication with th...   \n",
       "2                      i shouldn't have sold my boat   \n",
       "3    Bitches be like, It was my fault i made him mad   \n",
       "4  find a picture of 4 girls together on FB make ...   \n",
       "\n",
       "                           text_transcription_tokens  \n",
       "0  [dad, burn, jon, snow, stop, dad, know, happen...  \n",
       "1  [may, mixcommunication, decorator, happy, birt...  \n",
       "2                                  [n't, sold, boat]  \n",
       "3                  [bitches, like, fault, made, mad]  \n",
       "4  [find, picture, 4, girls, together, fb, make, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['text_transcription_tokens'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, word_to_id = create_vocabulary(sentences)\n",
    "vocabulary_size = len(vocabulary)\n",
    "max_length = max(map(lambda x: len(x), word_to_id.keys()))\n",
    "X = df['text_transcription_tokens'].apply(lambda x: np.array([word_to_id[i] for i in x])).values\n",
    "X_pad = pad_sequences(X, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,2:6].values.astype('float').reshape((-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Pre-Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"withoutInitializedWeights.misogenyType\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 50)          23500     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,664\n",
      "Trainable params: 115,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(name=\"withoutInitializedWeights.misogenyType\")\n",
    "model.add(Embedding(input_dim=vocabulary_size, output_dim=50))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.05), loss=categorical_crossentropy,  metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:50:00.262228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:50:00.262265: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ircnnih\" target=\"_blank\">withoutInitializedWeights.misogenyType</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 2s 35ms/step - loss: 0.4436 - accuracy: 0.2159 - f1_m: 0.2692 - precision_m: 0.2000 - recall_m: 0.4360\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4799 - accuracy: 0.2045 - f1_m: 0.2000 - precision_m: 0.1444 - recall_m: 0.3556\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3673 - accuracy: 0.2841 - f1_m: 0.3439 - precision_m: 0.2556 - recall_m: 0.6506\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3661 - accuracy: 0.3295 - f1_m: 0.3298 - precision_m: 0.2444 - recall_m: 0.5167\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3562 - accuracy: 0.3295 - f1_m: 0.2978 - precision_m: 0.2194 - recall_m: 0.4778\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3494 - accuracy: 0.3068 - f1_m: 0.2741 - precision_m: 0.2028 - recall_m: 0.4537\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3624 - accuracy: 0.2614 - f1_m: 0.2913 - precision_m: 0.2222 - recall_m: 0.4368\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3547 - accuracy: 0.3295 - f1_m: 0.2893 - precision_m: 0.2333 - recall_m: 0.3975\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3485 - accuracy: 0.3295 - f1_m: 0.3322 - precision_m: 0.2556 - recall_m: 0.4915\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3555 - accuracy: 0.3295 - f1_m: 0.2902 - precision_m: 0.2083 - recall_m: 0.4833\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3631 - accuracy: 0.3295 - f1_m: 0.2950 - precision_m: 0.2250 - recall_m: 0.5000\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3619 - accuracy: 0.3295 - f1_m: 0.3639 - precision_m: 0.2667 - recall_m: 0.6310\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3436 - accuracy: 0.3295 - f1_m: 0.2906 - precision_m: 0.2111 - recall_m: 0.5230\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3787 - accuracy: 0.3295 - f1_m: 0.4563 - precision_m: 0.3306 - recall_m: 0.8024\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3578 - accuracy: 0.3295 - f1_m: 0.3480 - precision_m: 0.2528 - recall_m: 0.6460\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3640 - accuracy: 0.3295 - f1_m: 0.3683 - precision_m: 0.2694 - recall_m: 0.6454\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3670 - accuracy: 0.3295 - f1_m: 0.3136 - precision_m: 0.2361 - recall_m: 0.4870\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3544 - accuracy: 0.3295 - f1_m: 0.2959 - precision_m: 0.2222 - recall_m: 0.4675\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3600 - accuracy: 0.2727 - f1_m: 0.2628 - precision_m: 0.1861 - recall_m: 0.5111\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3459 - accuracy: 0.3295 - f1_m: 0.4448 - precision_m: 0.3333 - recall_m: 0.7803\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3440 - accuracy: 0.3295 - f1_m: 0.4440 - precision_m: 0.3278 - recall_m: 0.7278\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3452 - accuracy: 0.3295 - f1_m: 0.4226 - precision_m: 0.3111 - recall_m: 0.6796\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3688 - accuracy: 0.3295 - f1_m: 0.2558 - precision_m: 0.1861 - recall_m: 0.4683\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3444 - accuracy: 0.2955 - f1_m: 0.2555 - precision_m: 0.1833 - recall_m: 0.4444\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3886 - accuracy: 0.2955 - f1_m: 0.2846 - precision_m: 0.2000 - recall_m: 0.5111\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3659 - accuracy: 0.3295 - f1_m: 0.3269 - precision_m: 0.2444 - recall_m: 0.5098\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3502 - accuracy: 0.3295 - f1_m: 0.3911 - precision_m: 0.2944 - recall_m: 0.6349\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3640 - accuracy: 0.3295 - f1_m: 0.2905 - precision_m: 0.2167 - recall_m: 0.4833\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3630 - accuracy: 0.3295 - f1_m: 0.3974 - precision_m: 0.3000 - recall_m: 0.6352\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3261 - accuracy: 0.3068 - f1_m: 0.4253 - precision_m: 0.3194 - recall_m: 0.7019\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3674 - accuracy: 0.2727 - f1_m: 0.2681 - precision_m: 0.2250 - recall_m: 0.3565\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4009 - accuracy: 0.3068 - f1_m: 0.2194 - precision_m: 0.1611 - recall_m: 0.3704\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3764 - accuracy: 0.2273 - f1_m: 0.2986 - precision_m: 0.2278 - recall_m: 0.4757\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4188 - accuracy: 0.2273 - f1_m: 0.3054 - precision_m: 0.2278 - recall_m: 0.5635\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3703 - accuracy: 0.2614 - f1_m: 0.2403 - precision_m: 0.1778 - recall_m: 0.3944\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3549 - accuracy: 0.3295 - f1_m: 0.3220 - precision_m: 0.2500 - recall_m: 0.5126\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3686 - accuracy: 0.2841 - f1_m: 0.3101 - precision_m: 0.2306 - recall_m: 0.5556\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3782 - accuracy: 0.3295 - f1_m: 0.3013 - precision_m: 0.2167 - recall_m: 0.5331\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3740 - accuracy: 0.2614 - f1_m: 0.2528 - precision_m: 0.2028 - recall_m: 0.3868\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3830 - accuracy: 0.2500 - f1_m: 0.2401 - precision_m: 0.1806 - recall_m: 0.3942\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3569 - accuracy: 0.3295 - f1_m: 0.4446 - precision_m: 0.3306 - recall_m: 0.8102\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3580 - accuracy: 0.2841 - f1_m: 0.2701 - precision_m: 0.2111 - recall_m: 0.4722\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3788 - accuracy: 0.3295 - f1_m: 0.4100 - precision_m: 0.2972 - recall_m: 0.7056\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3783 - accuracy: 0.2841 - f1_m: 0.2709 - precision_m: 0.2111 - recall_m: 0.3942\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3907 - accuracy: 0.3295 - f1_m: 0.2224 - precision_m: 0.1667 - recall_m: 0.3704\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3690 - accuracy: 0.3295 - f1_m: 0.4364 - precision_m: 0.3250 - recall_m: 0.7241\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3593 - accuracy: 0.3295 - f1_m: 0.3012 - precision_m: 0.2306 - recall_m: 0.4722\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3730 - accuracy: 0.2273 - f1_m: 0.2267 - precision_m: 0.1639 - recall_m: 0.3852\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3954 - accuracy: 0.2273 - f1_m: 0.2779 - precision_m: 0.2028 - recall_m: 0.4593\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3530 - accuracy: 0.3295 - f1_m: 0.2920 - precision_m: 0.2333 - recall_m: 0.4781\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4213 - accuracy: 0.2045 - f1_m: 0.2821 - precision_m: 0.2000 - recall_m: 0.5307\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.4290 - accuracy: 0.2500 - f1_m: 0.2739 - precision_m: 0.2000 - recall_m: 0.4630\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3918 - accuracy: 0.2727 - f1_m: 0.2759 - precision_m: 0.2111 - recall_m: 0.4183\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3696 - accuracy: 0.2386 - f1_m: 0.2984 - precision_m: 0.2111 - recall_m: 0.5519\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3673 - accuracy: 0.2500 - f1_m: 0.3267 - precision_m: 0.2333 - recall_m: 0.5815\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3911 - accuracy: 0.2727 - f1_m: 0.3192 - precision_m: 0.2444 - recall_m: 0.4704\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3782 - accuracy: 0.2614 - f1_m: 0.3306 - precision_m: 0.2444 - recall_m: 0.5657\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3819 - accuracy: 0.3295 - f1_m: 0.3212 - precision_m: 0.2444 - recall_m: 0.5333\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3770 - accuracy: 0.3295 - f1_m: 0.3026 - precision_m: 0.2222 - recall_m: 0.4907\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3645 - accuracy: 0.2955 - f1_m: 0.2465 - precision_m: 0.1778 - recall_m: 0.4185\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3593 - accuracy: 0.3295 - f1_m: 0.3306 - precision_m: 0.2389 - recall_m: 0.5500\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3662 - accuracy: 0.2727 - f1_m: 0.2536 - precision_m: 0.1889 - recall_m: 0.3963\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3891 - accuracy: 0.2841 - f1_m: 0.2747 - precision_m: 0.2111 - recall_m: 0.4360\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3696 - accuracy: 0.3295 - f1_m: 0.3339 - precision_m: 0.2389 - recall_m: 0.5921\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3723 - accuracy: 0.3295 - f1_m: 0.2863 - precision_m: 0.2083 - recall_m: 0.5370\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.4244 - accuracy: 0.2045 - f1_m: 0.2924 - precision_m: 0.2083 - recall_m: 0.5048\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4028 - accuracy: 0.2273 - f1_m: 0.2444 - precision_m: 0.1750 - recall_m: 0.4611\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3573 - accuracy: 0.3295 - f1_m: 0.4445 - precision_m: 0.3278 - recall_m: 0.7815\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3738 - accuracy: 0.2955 - f1_m: 0.3417 - precision_m: 0.2667 - recall_m: 0.5459\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3496 - accuracy: 0.2955 - f1_m: 0.2704 - precision_m: 0.2056 - recall_m: 0.4127\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3625 - accuracy: 0.2841 - f1_m: 0.3123 - precision_m: 0.2194 - recall_m: 0.6389\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3970 - accuracy: 0.2386 - f1_m: 0.3172 - precision_m: 0.2361 - recall_m: 0.5407\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3527 - accuracy: 0.3182 - f1_m: 0.2514 - precision_m: 0.1861 - recall_m: 0.4616\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3490 - accuracy: 0.2727 - f1_m: 0.3239 - precision_m: 0.2417 - recall_m: 0.5111\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3480 - accuracy: 0.3295 - f1_m: 0.4520 - precision_m: 0.3333 - recall_m: 0.7783\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3683 - accuracy: 0.3295 - f1_m: 0.3050 - precision_m: 0.2222 - recall_m: 0.5074\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3550 - accuracy: 0.2727 - f1_m: 0.3365 - precision_m: 0.2444 - recall_m: 0.5574\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3473 - accuracy: 0.3295 - f1_m: 0.4475 - precision_m: 0.3278 - recall_m: 0.7593\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3633 - accuracy: 0.3295 - f1_m: 0.4436 - precision_m: 0.3250 - recall_m: 0.8116\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4100 - accuracy: 0.2386 - f1_m: 0.2684 - precision_m: 0.1889 - recall_m: 0.4815\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3327 - accuracy: 0.3182 - f1_m: 0.3160 - precision_m: 0.2333 - recall_m: 0.5783\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3872 - accuracy: 0.2614 - f1_m: 0.2730 - precision_m: 0.2000 - recall_m: 0.4561\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3816 - accuracy: 0.2955 - f1_m: 0.3017 - precision_m: 0.2222 - recall_m: 0.5175\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3653 - accuracy: 0.2955 - f1_m: 0.2533 - precision_m: 0.1889 - recall_m: 0.4222\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3716 - accuracy: 0.3295 - f1_m: 0.3094 - precision_m: 0.2250 - recall_m: 0.5296\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3624 - accuracy: 0.3295 - f1_m: 0.3412 - precision_m: 0.2528 - recall_m: 0.6343\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3673 - accuracy: 0.2500 - f1_m: 0.2927 - precision_m: 0.2167 - recall_m: 0.4593\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3659 - accuracy: 0.3295 - f1_m: 0.2694 - precision_m: 0.1806 - recall_m: 0.5481\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3559 - accuracy: 0.3295 - f1_m: 0.3149 - precision_m: 0.2250 - recall_m: 0.5741\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4209 - accuracy: 0.2159 - f1_m: 0.2357 - precision_m: 0.1778 - recall_m: 0.3627\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3557 - accuracy: 0.2955 - f1_m: 0.3286 - precision_m: 0.2333 - recall_m: 0.5722\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3595 - accuracy: 0.3295 - f1_m: 0.3003 - precision_m: 0.2333 - recall_m: 0.4630\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4107 - accuracy: 0.2955 - f1_m: 0.2639 - precision_m: 0.1917 - recall_m: 0.4333\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3465 - accuracy: 0.3068 - f1_m: 0.3403 - precision_m: 0.2556 - recall_m: 0.5648\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3513 - accuracy: 0.2955 - f1_m: 0.3518 - precision_m: 0.2611 - recall_m: 0.5843\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3461 - accuracy: 0.3295 - f1_m: 0.4585 - precision_m: 0.3333 - recall_m: 0.7593\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3578 - accuracy: 0.2614 - f1_m: 0.3387 - precision_m: 0.2556 - recall_m: 0.5201\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3874 - accuracy: 0.2841 - f1_m: 0.3521 - precision_m: 0.2667 - recall_m: 0.5818\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3732 - accuracy: 0.2955 - f1_m: 0.4018 - precision_m: 0.2944 - recall_m: 0.6914\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3451 - accuracy: 0.3295 - f1_m: 0.4475 - precision_m: 0.3278 - recall_m: 0.7664\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3389 - accuracy: 0.3295 - f1_m: 0.3920 - precision_m: 0.2944 - recall_m: 0.6454\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3601 - accuracy: 0.2841 - f1_m: 0.2438 - precision_m: 0.1917 - recall_m: 0.3370\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3661 - accuracy: 0.3295 - f1_m: 0.3137 - precision_m: 0.2278 - recall_m: 0.5167\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3586 - accuracy: 0.3295 - f1_m: 0.4536 - precision_m: 0.3278 - recall_m: 0.7611\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3557 - accuracy: 0.3068 - f1_m: 0.2643 - precision_m: 0.2139 - recall_m: 0.3889\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3694 - accuracy: 0.3295 - f1_m: 0.3135 - precision_m: 0.2389 - recall_m: 0.4630\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3916 - accuracy: 0.2386 - f1_m: 0.2980 - precision_m: 0.2194 - recall_m: 0.4704\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3723 - accuracy: 0.2159 - f1_m: 0.2722 - precision_m: 0.1972 - recall_m: 0.4815\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3467 - accuracy: 0.3295 - f1_m: 0.2825 - precision_m: 0.2056 - recall_m: 0.4979\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3359 - accuracy: 0.3295 - f1_m: 0.3383 - precision_m: 0.2528 - recall_m: 0.5534\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3833 - accuracy: 0.2727 - f1_m: 0.3605 - precision_m: 0.2667 - recall_m: 0.6056\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3686 - accuracy: 0.3068 - f1_m: 0.3058 - precision_m: 0.2361 - recall_m: 0.4481\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3701 - accuracy: 0.3068 - f1_m: 0.2414 - precision_m: 0.1722 - recall_m: 0.4444\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3769 - accuracy: 0.2841 - f1_m: 0.2650 - precision_m: 0.2000 - recall_m: 0.4222\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4282 - accuracy: 0.2273 - f1_m: 0.2089 - precision_m: 0.1500 - recall_m: 0.3783\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4624 - accuracy: 0.2159 - f1_m: 0.2885 - precision_m: 0.2083 - recall_m: 0.5233\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.4063 - accuracy: 0.2727 - f1_m: 0.3480 - precision_m: 0.2583 - recall_m: 0.6190\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4307 - accuracy: 0.2500 - f1_m: 0.3266 - precision_m: 0.2444 - recall_m: 0.5241\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3652 - accuracy: 0.2614 - f1_m: 0.2878 - precision_m: 0.2111 - recall_m: 0.5241\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3734 - accuracy: 0.2955 - f1_m: 0.3275 - precision_m: 0.2444 - recall_m: 0.5582\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3763 - accuracy: 0.2841 - f1_m: 0.3295 - precision_m: 0.2444 - recall_m: 0.5500\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3550 - accuracy: 0.3182 - f1_m: 0.4006 - precision_m: 0.3028 - recall_m: 0.6880\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3515 - accuracy: 0.3295 - f1_m: 0.4048 - precision_m: 0.3000 - recall_m: 0.6704\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3412 - accuracy: 0.3295 - f1_m: 0.3623 - precision_m: 0.2778 - recall_m: 0.5809\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3565 - accuracy: 0.2841 - f1_m: 0.2735 - precision_m: 0.2083 - recall_m: 0.4037\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3680 - accuracy: 0.2386 - f1_m: 0.2894 - precision_m: 0.2083 - recall_m: 0.4907\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3603 - accuracy: 0.3295 - f1_m: 0.4424 - precision_m: 0.3278 - recall_m: 0.7898\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3559 - accuracy: 0.3295 - f1_m: 0.3786 - precision_m: 0.2778 - recall_m: 0.6204\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3482 - accuracy: 0.3295 - f1_m: 0.3867 - precision_m: 0.2944 - recall_m: 0.6561\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3749 - accuracy: 0.3295 - f1_m: 0.3026 - precision_m: 0.2222 - recall_m: 0.4778\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3868 - accuracy: 0.2841 - f1_m: 0.2586 - precision_m: 0.2000 - recall_m: 0.4630\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3795 - accuracy: 0.2500 - f1_m: 0.3332 - precision_m: 0.2417 - recall_m: 0.5481\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3934 - accuracy: 0.3295 - f1_m: 0.3173 - precision_m: 0.2278 - recall_m: 0.5902\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3537 - accuracy: 0.3295 - f1_m: 0.3789 - precision_m: 0.2806 - recall_m: 0.6249\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3645 - accuracy: 0.3295 - f1_m: 0.2670 - precision_m: 0.1917 - recall_m: 0.4704\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3466 - accuracy: 0.3295 - f1_m: 0.3305 - precision_m: 0.2500 - recall_m: 0.5250\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3644 - accuracy: 0.3295 - f1_m: 0.3803 - precision_m: 0.2750 - recall_m: 0.6778\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3641 - accuracy: 0.3295 - f1_m: 0.3892 - precision_m: 0.2806 - recall_m: 0.6759\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3915 - accuracy: 0.2386 - f1_m: 0.3506 - precision_m: 0.2556 - recall_m: 0.6270\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.4615 - accuracy: 0.1932 - f1_m: 0.2430 - precision_m: 0.1722 - recall_m: 0.4657\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.4436 - accuracy: 0.2045 - f1_m: 0.1979 - precision_m: 0.1472 - recall_m: 0.3759\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3252 - accuracy: 0.3295 - f1_m: 0.3096 - precision_m: 0.2222 - recall_m: 0.5370\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3559 - accuracy: 0.3295 - f1_m: 0.3821 - precision_m: 0.2778 - recall_m: 0.6556\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3676 - accuracy: 0.3295 - f1_m: 0.3398 - precision_m: 0.2556 - recall_m: 0.6220\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3673 - accuracy: 0.3295 - f1_m: 0.2673 - precision_m: 0.1944 - recall_m: 0.4722\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3758 - accuracy: 0.3295 - f1_m: 0.2774 - precision_m: 0.2111 - recall_m: 0.4460\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3864 - accuracy: 0.3068 - f1_m: 0.3576 - precision_m: 0.2694 - recall_m: 0.5889\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4116 - accuracy: 0.2159 - f1_m: 0.2917 - precision_m: 0.2167 - recall_m: 0.4648\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3753 - accuracy: 0.2614 - f1_m: 0.3025 - precision_m: 0.2361 - recall_m: 0.4341\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3955 - accuracy: 0.2273 - f1_m: 0.3052 - precision_m: 0.2333 - recall_m: 0.5180\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4120 - accuracy: 0.2500 - f1_m: 0.2527 - precision_m: 0.1972 - recall_m: 0.3590\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3950 - accuracy: 0.2727 - f1_m: 0.2752 - precision_m: 0.2028 - recall_m: 0.4889\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3227 - accuracy: 0.3295 - f1_m: 0.3899 - precision_m: 0.3139 - recall_m: 0.6110\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3435 - accuracy: 0.2841 - f1_m: 0.4101 - precision_m: 0.2944 - recall_m: 0.6958\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3869 - accuracy: 0.2159 - f1_m: 0.2105 - precision_m: 0.1556 - recall_m: 0.3638\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3487 - accuracy: 0.3068 - f1_m: 0.3209 - precision_m: 0.2444 - recall_m: 0.5090\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3715 - accuracy: 0.2955 - f1_m: 0.3237 - precision_m: 0.2389 - recall_m: 0.5259\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3530 - accuracy: 0.3295 - f1_m: 0.4406 - precision_m: 0.3306 - recall_m: 0.7000\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3682 - accuracy: 0.3295 - f1_m: 0.3037 - precision_m: 0.2278 - recall_m: 0.5813\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3530 - accuracy: 0.3295 - f1_m: 0.3355 - precision_m: 0.2528 - recall_m: 0.5463\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3764 - accuracy: 0.3295 - f1_m: 0.2509 - precision_m: 0.1806 - recall_m: 0.4370\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3840 - accuracy: 0.3295 - f1_m: 0.4416 - precision_m: 0.3278 - recall_m: 0.7500\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4011 - accuracy: 0.2955 - f1_m: 0.2281 - precision_m: 0.1667 - recall_m: 0.4471\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3918 - accuracy: 0.3295 - f1_m: 0.3776 - precision_m: 0.2778 - recall_m: 0.6124\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3282 - accuracy: 0.3295 - f1_m: 0.4383 - precision_m: 0.3306 - recall_m: 0.7460\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3971 - accuracy: 0.3295 - f1_m: 0.1887 - precision_m: 0.1333 - recall_m: 0.3500\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3751 - accuracy: 0.2955 - f1_m: 0.3091 - precision_m: 0.2333 - recall_m: 0.5008\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3462 - accuracy: 0.3295 - f1_m: 0.3922 - precision_m: 0.2944 - recall_m: 0.6537\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3578 - accuracy: 0.3295 - f1_m: 0.2529 - precision_m: 0.1944 - recall_m: 0.3709\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.3656 - accuracy: 0.3295 - f1_m: 0.3001 - precision_m: 0.2139 - recall_m: 0.5630\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3547 - accuracy: 0.3295 - f1_m: 0.3910 - precision_m: 0.2889 - recall_m: 0.6876\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.3634 - accuracy: 0.3295 - f1_m: 0.3905 - precision_m: 0.2861 - recall_m: 0.6333\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.3654 - accuracy: 0.2614 - f1_m: 0.2800 - precision_m: 0.2083 - recall_m: 0.4481\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3590 - accuracy: 0.3295 - f1_m: 0.3827 - precision_m: 0.2722 - recall_m: 0.6802\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3623 - accuracy: 0.3295 - f1_m: 0.3234 - precision_m: 0.2361 - recall_m: 0.5463\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3317 - accuracy: 0.3295 - f1_m: 0.4120 - precision_m: 0.3000 - recall_m: 0.6963\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3904 - accuracy: 0.2727 - f1_m: 0.2341 - precision_m: 0.1778 - recall_m: 0.3601\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.3626 - accuracy: 0.3068 - f1_m: 0.2772 - precision_m: 0.2111 - recall_m: 0.4376\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.3957 - accuracy: 0.2727 - f1_m: 0.2895 - precision_m: 0.2139 - recall_m: 0.4981\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3599 - accuracy: 0.2614 - f1_m: 0.3298 - precision_m: 0.2556 - recall_m: 0.4870\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.3627 - accuracy: 0.3295 - f1_m: 0.2799 - precision_m: 0.2000 - recall_m: 0.5019\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3515 - accuracy: 0.3295 - f1_m: 0.4091 - precision_m: 0.3083 - recall_m: 0.6458\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3783 - accuracy: 0.2500 - f1_m: 0.2854 - precision_m: 0.2111 - recall_m: 0.5324\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3614 - accuracy: 0.2500 - f1_m: 0.2564 - precision_m: 0.1861 - recall_m: 0.4894\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.4039 - accuracy: 0.2727 - f1_m: 0.2420 - precision_m: 0.1778 - recall_m: 0.3987\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3546 - accuracy: 0.2955 - f1_m: 0.3072 - precision_m: 0.2278 - recall_m: 0.5193\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3544 - accuracy: 0.3295 - f1_m: 0.4599 - precision_m: 0.3333 - recall_m: 0.7704\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3612 - accuracy: 0.3295 - f1_m: 0.3456 - precision_m: 0.2500 - recall_m: 0.6250\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3653 - accuracy: 0.3182 - f1_m: 0.2536 - precision_m: 0.1833 - recall_m: 0.4407\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3722 - accuracy: 0.2386 - f1_m: 0.2877 - precision_m: 0.2083 - recall_m: 0.4926\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3600 - accuracy: 0.3295 - f1_m: 0.3736 - precision_m: 0.2778 - recall_m: 0.6222\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3564 - accuracy: 0.3295 - f1_m: 0.2840 - precision_m: 0.2083 - recall_m: 0.4630\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.3567 - accuracy: 0.2955 - f1_m: 0.3255 - precision_m: 0.2361 - recall_m: 0.5426\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3401 - accuracy: 0.3295 - f1_m: 0.3466 - precision_m: 0.2583 - recall_m: 0.5444\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3763 - accuracy: 0.2386 - f1_m: 0.3280 - precision_m: 0.2444 - recall_m: 0.5815\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3682 - accuracy: 0.2273 - f1_m: 0.2852 - precision_m: 0.2056 - recall_m: 0.5011\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3429 - accuracy: 0.3295 - f1_m: 0.3726 - precision_m: 0.2806 - recall_m: 0.6605\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 0.3831 - accuracy: 0.2614 - f1_m: 0.2757 - precision_m: 0.2139 - recall_m: 0.4127\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.3488 - accuracy: 0.3068 - f1_m: 0.3178 - precision_m: 0.2389 - recall_m: 0.5201\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.3846 - accuracy: 0.2614 - f1_m: 0.2257 - precision_m: 0.1694 - recall_m: 0.3656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bd04484c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3715\n",
      "Test accuracy: 0.5000\n",
      "Test f1_score: 0.6250\n",
      "Test precision: 0.5000\n",
      "Test recall: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2788... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇████▇█▅█▄▅▅█▃█▄██▅▅▂▇▄▇████▂▅████▇▄██▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▁▃▆▆▇▅▂▄▃█▃▄▃█▄█▃▃▄▅▂▃▄▅▇▆▆▆▅▄▇█▆▆▆▃▃▅▅▂</td></tr><tr><td>loss</td><td>█▁▂▂▁▂▄▂▂▂▅▄▂▂▄▁▃▂▂▃▂▃▂▆▂▂▂▂▂▅▁▂▄▁▂▂▂▂▁▃</td></tr><tr><td>precision_m</td><td>▁▃▆▆▇▅▂▅▄█▃▅▃█▄█▃▂▄▆▃▃▄▅▇▆▆▆▅▄▇█▆▇▆▄▃▅▅▂</td></tr><tr><td>recall_m</td><td>▁▃▆▆▆▄▂▄▃▇▃▃▂█▄█▃▄▃▅▁▃▃▄▇▅▆▆▅▃▇▇▅▆▆▃▃▆▄▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.26136</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1_m</td><td>0.22568</td></tr><tr><td>loss</td><td>0.38463</td></tr><tr><td>precision_m</td><td>0.16944</td></tr><tr><td>recall_m</td><td>0.36561</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">withoutInitializedWeights.misogenyType</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ircnnih\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/1ircnnih</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_214958-1ircnnih/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec.50d.misogenyType\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, None, 50)          23500     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 64)                29440     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,200\n",
      "Trainable params: 53,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(name=\"word2vec.50d.misogenyType\")\n",
    "model.add(Embedding(input_dim=len(vocabulary), output_dim=50, weights=[embeddings[50]]))\n",
    "model.add(LSTM(units=64, activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.05), loss=categorical_crossentropy,  metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:51:15.527647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:51:15.527690: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/o7bbba74\" target=\"_blank\">word2vec.50d.misogenyType</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 42ms/step - loss: 3.4588 - accuracy: 0.3295 - f1_m: 0.1333 - precision_m: 0.0938 - recall_m: 0.2308\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 51.8492 - accuracy: 0.2045 - f1_m: 0.0145 - precision_m: 0.0104 - recall_m: 0.0238\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5183 - accuracy: 0.3295 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 332.3225 - accuracy: 0.1591 - f1_m: 0.2188 - precision_m: 0.1562 - recall_m: 0.3661\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 19613944.0000 - accuracy: 0.2045 - f1_m: 0.2546 - precision_m: 0.1979 - recall_m: 0.3704\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15316484737728512.0000 - accuracy: 0.0909 - f1_m: 0.1206 - precision_m: 0.0868 - recall_m: 0.2020\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5341 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bf0106b20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=200, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3ca4e6daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test loss: nan\n",
      "Test accuracy: 0.5000\n",
      "Test f1_score: nan\n",
      "Test precision: nan\n",
      "Test recall: nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2902... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃▁██████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▁█                                      </td></tr><tr><td>loss</td><td>▁█                                      </td></tr><tr><td>precision_m</td><td>▁█                                      </td></tr><tr><td>recall_m</td><td>▁█                                      </td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59091</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1_m</td><td>nan</td></tr><tr><td>loss</td><td>nan</td></tr><tr><td>precision_m</td><td>nan</td></tr><tr><td>recall_m</td><td>nan</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">word2vec.50d.misogenyType</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/o7bbba74\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/o7bbba74</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_215114-o7bbba74/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec.50d.misogenyType\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 50)          23500     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                29440     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,200\n",
      "Trainable params: 53,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(name=\"word2vec.50d.misogenyType\")\n",
    "model.add(Embedding(input_dim=len(vocabulary), output_dim=50, weights=[embeddings[50]]))\n",
    "model.add(LSTM(units=64, activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.05), loss=categorical_crossentropy,  metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 21:51:50.906277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-14 21:51:50.906329: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/gl3ctebo\" target=\"_blank\">word2vec.50d.misogenyType</a></strong> to <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 40ms/step - loss: 1.1923 - accuracy: 0.1136 - f1_m: 0.1554 - precision_m: 0.1076 - recall_m: 0.2803\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5316 - accuracy: 0.3295 - f1_m: 0.1250 - precision_m: 0.0870 - recall_m: 0.2222\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 5.5144 - accuracy: 0.3295 - f1_m: 0.3422 - precision_m: 0.2465 - recall_m: 0.5671       \n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 23.9572 - accuracy: 0.3182 - f1_m: 0.3311 - precision_m: 0.2788 - recall_m: 0.4263\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3752335872.0000 - accuracy: 0.3068 - f1_m: 0.3934 - precision_m: 0.3223 - recall_m: 0.5358\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 30666157752905105408.0000 - accuracy: 0.3295 - f1_m: 0.4314 - precision_m: 0.3364 - recall_m: 0.6098\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 41ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 43ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.5909 - f1_m: nan - precision_m: nan - recall_m: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca4e64520>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(reinit=True, name=model.name)\n",
    "model.fit(X_train, y_train, epochs=200, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3bf0541c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test loss: nan\n",
      "Test accuracy: 0.5000\n",
      "Test f1_score: nan\n",
      "Test precision: nan\n",
      "Test recall: nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3010... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1_m</td><td>▁█                                      </td></tr><tr><td>loss</td><td>▁█                                      </td></tr><tr><td>precision_m</td><td>▁█                                      </td></tr><tr><td>recall_m</td><td>▁█                                      </td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59091</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>f1_m</td><td>nan</td></tr><tr><td>loss</td><td>nan</td></tr><tr><td>precision_m</td><td>nan</td></tr><tr><td>recall_m</td><td>nan</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">word2vec.50d.misogenyType</strong>: <a href=\"https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/gl3ctebo\" target=\"_blank\">https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2/runs/gl3ctebo</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211114_215149-gl3ctebo/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "print(f'Test f1_score: {f1_score:.4f}')\n",
    "print(f'Test precision: {precision:.4f}')\n",
    "print(f'Test recall: {recall:.4f}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WANDB was used to track the training process along with the evaluation, all of the results are available at the [link](https://wandb.ai/aleksandar1932/NLP_2021-Laboratory%20Exercises_2?workspace=user-aleksandar1932).\n",
    "\n",
    "*Runs are postfixed with `.misogenyType`*."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02d0b1b3f612c4c5e51656c8d0ea12cc8bdc13c9ac193c394dc1e17c8d0fd734"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('nlp-2021-n': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
